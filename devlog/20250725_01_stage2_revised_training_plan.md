### **Stage-2 훈련 계획: 안정성 및 핵심 기호 검출 중심**

**작성일**: 2025년 7월 25일
**문서 목적**: Stage-1 훈련의 실패 원인 분석을 바탕으로, 안정적인 훈련을 보장하고 핵심 악보 기호 검출에 집중하는 새로운 훈련 계획을 수립한다.

---

### **1. 핵심 전략 변경: "모든 것 감지"에서 "핵심 감지 후 재구성"으로**

Stage-1의 가장 큰 문제점은 제한된 리소스(11GB VRAM)로 너무 많은 것을 하려 했다는 점입니다. Stage-2에서는 접근 방식을 근본적으로 변경합니다.

-   **기존 전략**: `stem`, `ledgerLine` 등 모든 요소를 모델이 직접 감지하도록 시도.
-   **신규 전략**: 
    1.  모델은 **형태가 명확하고 중요한 핵심 기호**(`notehead`, `clef`, `rest` 등) 감지에만 집중한다.
    2.  `stem`(기둥), `ledgerLine`(덧줄)처럼 가늘고 정보량이 적지만, 규칙성이 강한 요소는 **학습 대상에서 제외**한다.
    3.  제외된 요소들은 훈련 후, 검출된 핵심 기호의 위치를 기반으로 **후처리(Post-processing) 알고리즘을 통해 완벽하게 재구성**한다.

**기대 효과**: 모델의 학습 부담을 줄여 핵심 기호의 검출 정확도를 높이고, 이미지 크기 축소로 인한 정보 손실 문제를 원천적으로 해결하며, 안정적인 배치 크기를 확보하여 훈련 실패 위험을 최소화합니다.

---

### **2. Stage-1 실패 원인 요약**

-   **복합적 원인**: `imgsz=1536`으로 인한 **메모리 초과** → 이로 인한 **`batch=1`** 설정 → 불안정한 Gradient 상태에서 **`lr=0.01`**이라는 높은 학습률 적용 → **Gradient 폭발**로 인한 **`nan` Loss** 발생.

---

### **3. Stage-2 상세 실행 계획**

#### **3.1. 데이터셋 및 클래스 재정의**

1.  **제외할 클래스**: 
    -   `stem`
    -   `ledgerLine`
    -   (선택) `beam` 또한 `notehead` 간의 관계로 재구성 가능하므로 초기 단계에서는 제외 고려.

2.  **수정 대상 파일**: 
    -   `preprocess_deepscores.py`: 클래스 필터링 로직을 수정하여 위 클래스들을 어노테이션 생성 시 제외하도록 변경합니다.
    -   `deepscores_stage2.yaml` (가칭): 새로운 클래스 목록으로 `names` 섹션을 업데이트합니다.

#### **3.2. 하이퍼파라미터 전면 수정**

다음과 같이 안정성에 초점을 맞춘 하이퍼파라미터를 설정합니다.

| 파라미터            | Stage-1 (실패) | **Stage-2 (신규)** | 이유                                         |
| ------------------- | -------------- | ------------------ | -------------------------------------------- |
| `imgsz`             | 1536           | **1024**           | 메모리 사용량 감소, VRAM 내 안정적 실행      |
| `batch`             | 1              | **2 ~ 4**          | 안정적인 Gradient 확보 (핵심)                |
| `lr0` (학습률)      | 0.01           | **0.001**          | Loss 발산 방지, 안정적인 수렴 유도           |
| `optimizer`         | AdamW          | **SGD**            | 더 안정적인 가중치 업데이트                  |
| `warmup_epochs`     | 3              | **5**              | 부드러운 학습 시작, 초기 불안정성 억제       |
| `gradient_clipping` | (미사용)       | **10.0**           | Gradient 폭발을 막는 안전장치                |
| `mosaic`            | 0.0            | **0.0**            | 메모리 절약을 위해 모자이크 증강 비활성화 유지 |
| `amp` (Mixed Prec)  | True           | **False (초기)**   | 수치적 안정성 확보 (안정화 후 True로 재시도) |

#### **3.3. 실행 단계**

1.  **[데이터 준비]** `preprocess_deepscores.py`를 수정하여 `stem`, `ledgerLine`을 제외한 새로운 라벨 파일을 생성합니다. 새로운 `deepscores_stage2.yaml` 파일을 준비합니다.

2.  **[훈련 실행]** 위의 수정된 하이퍼파라미터로 훈련 스크립트(`train_stage2.py` 등)를 실행합니다. `nvidia-smi`로 GPU 메모리 사용량을 모니터링하며, 여유가 있다면 배치 크기를 3 또는 4로 늘리는 것을 고려합니다.

3.  **[성능 검증]** 훈련이 안정적으로 완료되면, 검증 세트에 대한 **핵심 기호**들의 mAP, 정밀도, 재현율을 평가합니다.

4.  **[후처리 개발]** **새로운 핵심 과제**: 검출된 결과를 입력으로 받아 `stem`과 `ledgerLine`을 재구성하는 Python 스크립트를 개발합니다.
    -   **입력**: `notehead`의 BBox 리스트, 오선(staff)의 위치 정보.
    -   **로직**: 
        -   `notehead`의 y좌표와 오선 위치를 비교하여 덧줄 필요 여부 및 개수 계산.
        -   음악 기보법 규칙에 따라 `notehead`에 기둥(stem)을 올바른 방향과 길이로 추가.
    -   **출력**: 완전한 악보 정보 (시각화 또는 MusicXML 데이터 구조).

### **4. 예상 결과**

-   `nan` Loss 없이 훈련이 안정적으로 완료됩니다.
-   `notehead`, `clef`, `rest` 등 형태가 명확한 핵심 기호에 대해 높은 검출 정확도를 보이는 모델을 얻습니다.
-   후처리 로직을 통해, 모델이 직접 감지한 것보다 더 일관되고 정확한 `stem`과 `ledgerLine`을 가진 최종 결과물을 생성할 수 있습니다.
