### **DeepScores ê¸°ë°˜ YOLOv8 ìŒí‘œ ì¸ì‹ ëª¨ë¸ ìƒì„¸ êµ¬í˜„ ê³„íš**

#### **ğŸ¯ ìµœì¢… ëª©í‘œ**
- DeepScores ë°ì´í„°ì…‹ìœ¼ë¡œ í•™ìŠµëœ YOLOv8 ëª¨ë¸(`best.pt`)ì„ í™•ë³´í•œë‹¤.
- ì´ ëª¨ë¸ì„ `ScoreEye` í”„ë¡œì íŠ¸ì— í†µí•©í•˜ì—¬, `extract_measures.py`ë¡œ ì¶”ì¶œëœ ë§ˆë”” ì´ë¯¸ì§€ ë‚´ì˜ ê°œë³„ ì•…ë³´ ê¸°í˜¸(ìŒí‘œ, ì‰¼í‘œ ë“±)ë¥¼ ê°ì§€í•˜ëŠ” ê¸°ëŠ¥ì„ êµ¬í˜„í•œë‹¤.

---

### **Phase 1: í™˜ê²½ ì„¤ì • ë° ë°ì´í„° ì¤€ë¹„ (1ì¼)**

1.  **í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜**:
    - `requirements.txt` íŒŒì¼ì— ë‹¤ìŒ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì¶”ê°€í•˜ê³  ì„¤ì¹˜í•©ë‹ˆë‹¤.
      ```
      ultralytics
      numpy
      opencv-python
      pyyaml
      tqdm
      ```
    - ì„¤ì¹˜ ëª…ë ¹ì–´:
      ```bash
      pip install -r requirements.txt
      ```

2.  **DeepScores ë°ì´í„°ì…‹ ë‹¤ìš´ë¡œë“œ**:
    - ê³µì‹ ì›¹ì‚¬ì´íŠ¸(https://deepscores.org/dataset/)ì—ì„œ "DeepScoresV2 (Main dataset)"ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
    - ë‹¤ìš´ë¡œë“œ ë°›ì€ íŒŒì¼ì˜ ì••ì¶•ì„ `dataset/deepscores_v2` ì™€ ê°™ì€ ë””ë ‰í„°ë¦¬ì— í•´ì œí•©ë‹ˆë‹¤.

3.  **í”„ë¡œì íŠ¸ ë””ë ‰í„°ë¦¬ êµ¬ì¡° ì„¤ì •**:
    - ë°ì´í„°ì…‹ ë³€í™˜ ë° í•™ìŠµì„ ìœ„í•´ ë‹¤ìŒê³¼ ê°™ì€ êµ¬ì¡°ë¥¼ í”„ë¡œì íŠ¸ ë£¨íŠ¸ì— ìƒì„±í•©ë‹ˆë‹¤.
      ```
      ScoreEye/
      â”œâ”€â”€ deepscores_workspace/
      â”‚   â”œâ”€â”€ data/                 # YOLOv8 í•™ìŠµìš© ë°ì´í„°ì…‹ ìµœì¢… ìœ„ì¹˜
      â”‚   â”‚   â”œâ”€â”€ images/
      â”‚   â”‚   â”‚   â”œâ”€â”€ train/
      â”‚   â”‚   â”‚   â””â”€â”€ val/
      â”‚   â”‚   â”œâ”€â”€ labels/
      â”‚   â”‚   â”‚   â”œâ”€â”€ train/
      â”‚   â”‚   â”‚   â””â”€â”€ val/
      â”‚   â”‚   â””â”€â”€ deepscores.yaml   # ë°ì´í„°ì…‹ ì„¤ì • íŒŒì¼
      â”‚   â”œâ”€â”€ raw_data/             # ë‹¤ìš´ë¡œë“œí•œ DeepScores ì›ë³¸ ë°ì´í„° ìœ„ì¹˜
      â”‚   â””â”€â”€ preprocess_deepscores.py # ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸
      â”œâ”€â”€ ... (ê¸°ì¡´ íŒŒì¼ë“¤)
      ```

---

### **Phase 2: ë°ì´í„° ì „ì²˜ë¦¬ ë° ë³€í™˜ (2-3ì¼)**

ì´ ë‹¨ê³„ê°€ ê°€ì¥ ì¤‘ìš”í•˜ë©°, `preprocess_deepscores.py` ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±ì´ í•µì‹¬ì…ë‹ˆë‹¤.

1.  **ëŒ€ìƒ í´ë˜ìŠ¤ ì„ ì • ë° ë§¤í•‘**:
    - DeepScoresëŠ” 135ê°œì˜ í´ë˜ìŠ¤ë¥¼ ì œê³µí•˜ì§€ë§Œ, ì´ˆê¸° ëª¨ë¸ì€ í•µì‹¬ í´ë˜ìŠ¤ì— ì§‘ì¤‘í•©ë‹ˆë‹¤.
    - **ì´ˆê¸° ëª©í‘œ í´ë˜ìŠ¤ (10ê°œ)**:
      - `noteheadFull` (ì±„ì›Œì§„ ìŒí‘œ ë¨¸ë¦¬)
      - `noteheadHalf` (ë¹ˆ ìŒí‘œ ë¨¸ë¦¬)
      - `noteheadWhole` (ì˜¨ìŒí‘œ ë¨¸ë¦¬)
      - `stem` (ê¸°ë‘¥)
      - `beam` (ë¹”)
      - `dot` (ì )
      - `gClef` (ë†’ì€ìŒìë¦¬í‘œ)
      - `fClef` (ë‚®ì€ìŒìë¦¬í‘œ)
      - `restQuarter` (4ë¶„ ì‰¼í‘œ)
      - `restHalf` (2ë¶„ ì‰¼í‘œ)
    - ì´ í´ë˜ìŠ¤ë“¤ì„ `0`ë¶€í„° ì‹œì‘í•˜ëŠ” ì •ìˆ˜ ì¸ë±ìŠ¤ë¡œ ë§¤í•‘í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ë¥¼ ìŠ¤í¬ë¦½íŠ¸ ë‚´ì— ì •ì˜í•©ë‹ˆë‹¤.

2.  **`preprocess_deepscores.py` ìŠ¤í¬ë¦½íŠ¸ êµ¬í˜„**:
    - ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒ ê¸°ëŠ¥ì„ ìˆ˜í–‰í•´ì•¼ í•©ë‹ˆë‹¤.

    ```python
    # preprocess_deepscores.py

    import numpy as np
    import os
    import cv2
    from tqdm import tqdm
    from sklearn.model_selection import train_test_split

    # 1. ì„¤ì • ë³€ìˆ˜
    RAW_DATA_DIR = 'raw_data/ds2_dense'
    OUTPUT_DIR = 'data'
    TARGET_CLASSES = {
        'noteheadFull': 0, 'noteheadHalf': 1, 'noteheadWhole': 2,
        'stem': 3, 'beam': 4, 'dot': 5, 'gClef': 6, 'fClef': 7,
        'restQuarter': 8, 'restHalf': 9
    }
    IMAGE_SIZE = 1024 # DeepScoresëŠ” ê³ í•´ìƒë„ì´ë¯€ë¡œ 1024 ê¶Œì¥
    TRAIN_RATIO = 0.85

    def convert_to_yolo(bbox, img_width, img_height):
        # DeepScores bbox [x_min, y_min, x_max, y_max] -> YOLO í¬ë§· ë³€í™˜
        dw = 1. / img_width
        dh = 1. / img_height
        x_center = (bbox[0] + bbox[2]) / 2.0
        y_center = (bbox[1] + bbox[3]) / 2.0
        width = bbox[2] - bbox[0]
        height = bbox[3] - bbox[1]
        return (x_center * dw, y_center * dh, width * dw, height * dh)

    def process_dataset():
        # 2. ì´ë¯¸ì§€ì™€ NPZ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        all_images = [f for f in os.listdir(os.path.join(RAW_DATA_DIR, 'images')) if f.endswith('.png')]
        
        # 3. Train/Validation ë¶„í• 
        train_images, val_images = train_test_split(all_images, train_size=TRAIN_RATIO, random_state=42)

        # 4. ë°ì´í„°ì…‹ ë£¨í”„ (train, val)
        for subset, image_list in [('train', train_images), ('val', val_images)]:
            img_path = os.path.join(OUTPUT_DIR, 'images', subset)
            lbl_path = os.path.join(OUTPUT_DIR, 'labels', subset)
            os.makedirs(img_path, exist_ok=True)
            os.makedirs(lbl_path, exist_ok=True)

            for img_name in tqdm(image_list, desc=f"Processing {subset} set"):
                # 5. ì›ë³¸ ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ ë° ì €ì¥
                original_img = cv2.imread(os.path.join(RAW_DATA_DIR, 'images', img_name))
                h, w, _ = original_img.shape
                resized_img = cv2.resize(original_img, (IMAGE_SIZE, IMAGE_SIZE))
                cv2.imwrite(os.path.join(img_path, img_name), resized_img)

                # 6. NPZ ì–´ë…¸í…Œì´ì…˜ ë¡œë“œ ë° íŒŒì‹±
                npz_path = os.path.join(RAW_DATA_DIR, 'annotations_npz', img_name.replace('.png', '.npz'))
                annotations = np.load(npz_path, allow_pickle=True)['arr_0']
                
                yolo_labels = []
                for ann in annotations:
                    class_name = ann['class_name']
                    if class_name in TARGET_CLASSES:
                        class_id = TARGET_CLASSES[class_name]
                        bbox = ann['bbox'] # [x_min, y_min, x_max, y_max]
                        
                        # 7. YOLO í¬ë§·ìœ¼ë¡œ ë³€í™˜
                        yolo_bbox = convert_to_yolo(bbox, w, h)
                        yolo_labels.append(f"{class_id} {' '.join(map(str, yolo_bbox))}")

                # 8. ë¼ë²¨ íŒŒì¼ ì €ì¥
                with open(os.path.join(lbl_path, img_name.replace('.png', '.txt')), 'w') as f:
                    f.write('
'.join(yolo_labels))

    if __name__ == '__main__':
        process_dataset()
        print("DeepScores dataset conversion to YOLOv8 format is complete.")

    ```

3.  **ë³€í™˜ ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰**:
    ```bash
    cd deepscores_workspace
    python preprocess_deepscores.py
    ```
    - ì‹¤í–‰ì´ ì™„ë£Œë˜ë©´ `deepscores_workspace/data` ë””ë ‰í„°ë¦¬ì— í•™ìŠµ ì¤€ë¹„ê°€ ì™„ë£Œëœ ë°ì´í„°ê°€ ìƒì„±ë©ë‹ˆë‹¤.

---

### **Phase 3: ëª¨ë¸ í•™ìŠµ (2-4ì¼)**

1.  **`deepscores.yaml` íŒŒì¼ ìƒì„±**:
    - `deepscores_workspace/data` ë””ë ‰í„°ë¦¬ì— ë‹¤ìŒ ë‚´ìš©ìœ¼ë¡œ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.

    ```yaml
    # deepscores.yaml
    path: /home/user/projects/ScoreEye/deepscores_workspace/data  # ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš© ê¶Œì¥
    train: images/train
    val: images/val

    # Classes
    names:
      0: noteheadFull
      1: noteheadHalf
      2: noteheadWhole
      3: stem
      4: beam
      5: dot
      6: gClef
      7: fClef
      8: restQuarter
      9: restHalf
    ```

2.  **ì´ˆê¸° í…ŒìŠ¤íŠ¸ í•™ìŠµ (Sanity Check)**:
    - ì „ì²´ íŒŒì´í”„ë¼ì¸ì´ ì •ìƒ ë™ì‘í•˜ëŠ”ì§€ í™•ì¸í•˜ê¸° ìœ„í•´ ì ì€ epochìœ¼ë¡œ ë¹ ë¥´ê²Œ í•™ìŠµì„ ì‹¤í–‰í•©ë‹ˆë‹¤.
    - í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í„°ë¦¬(`ScoreEye/`)ì—ì„œ ì‹¤í–‰í•©ë‹ˆë‹¤.

    ```bash
    yolo task=detect mode=train model=yolov8n.pt data=./deepscores_workspace/data/deepscores.yaml epochs=5 imgsz=1024 batch=16
    ```

3.  **ë³¸ í•™ìŠµ ì‹¤í–‰**:
    - í…ŒìŠ¤íŠ¸ í•™ìŠµì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ë©´, ì¶©ë¶„í•œ epochìœ¼ë¡œ ë³¸ í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.
    - `patience` ì˜µì…˜ì€ val lossê°€ ê°œì„ ë˜ì§€ ì•Šì„ ë•Œ ì¡°ê¸° ì¢…ë£Œí•˜ì—¬ ì‹œê°„ì„ ì ˆì•½í•©ë‹ˆë‹¤.

    ```bash
    yolo task=detect mode=train model=yolov8s.pt data=./deepscores_workspace/data/deepscores.yaml epochs=100 imgsz=1024 batch=8 patience=10
    ```
    - `yolov8s.pt` (Small) ëª¨ë¸ë¡œ ì‹œì‘í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•˜ë©°, ì„±ëŠ¥ì— ë”°ë¼ `m` ë˜ëŠ” `l` ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    - í•™ìŠµì´ ì™„ë£Œë˜ë©´ `runs/detect/train/weights/best.pt` ê²½ë¡œì— ìµœì ì˜ ëª¨ë¸ ê°€ì¤‘ì¹˜ íŒŒì¼ì´ ìƒì„±ë©ë‹ˆë‹¤.

---

### **Phase 4: ì¶”ë¡  ë° í”„ë¡œì íŠ¸ í†µí•© (2ì¼)**

1.  **í•™ìŠµëœ ëª¨ë¸ ì´ë™**:
    - ìƒì„±ëœ `best.pt` íŒŒì¼ì„ í”„ë¡œì íŠ¸ì˜ `models/` ì™€ ê°™ì€ ê´€ë¦¬ ë””ë ‰í„°ë¦¬ë¡œ ë³µì‚¬í•˜ê³ , `deepscores_yolov8s.pt` ì™€ ê°™ì´ ì´ë¦„ì„ ë³€ê²½í•©ë‹ˆë‹¤.

2.  **ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸ ì‘ì„± (`symbol_detector.py`)**:
    - ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë§ˆë”” ì´ë¯¸ì§€ë¥¼ ì…ë ¥ë°›ì•„ ê¸°í˜¸ë“¤ì„ ê°ì§€í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ëŠ” ì—­í• ì„ í•©ë‹ˆë‹¤.

    ```python
    # symbol_detector.py
    from ultralytics import YOLO
    import cv2

    class SymbolDetector:
        def __init__(self, model_path):
            self.model = YOLO(model_path)

        def detect(self, image_path_or_np_array):
            """
            ì´ë¯¸ì§€ì—ì„œ ì•…ë³´ ê¸°í˜¸ë¥¼ ê°ì§€í•©ë‹ˆë‹¤.
            
            Returns:
                A list of dictionaries, each containing 'box', 'class_name', 'confidence'.
            """
            results = self.model(image_path_or_np_array, verbose=False)
            
            detected_symbols = []
            for r in results:
                boxes = r.boxes
                for box in boxes:
                    x1, y1, x2, y2 = map(int, box.xyxy[0])
                    conf = float(box.conf[0])
                    cls_id = int(box.cls[0])
                    class_name = self.model.names[cls_id]
                    
                    detected_symbols.append({
                        'box': (x1, y1, x2, y2),
                        'class_name': class_name,
                        'confidence': conf
                    })
            return detected_symbols

    if __name__ == '__main__':
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        detector = SymbolDetector('models/deepscores_yolov8s.pt')
        
        # extract_measures.pyë¡œ ì¶”ì¶œëœ ë§ˆë”” ì´ë¯¸ì§€ ê²½ë¡œ
        measure_image_path = 'output/measures/00_page/00_001.png' 
        
        symbols = detector.detect(measure_image_path)
        
        image = cv2.imread(measure_image_path)
        for sym in symbols:
            x1, y1, x2, y2 = sym['box']
            label = f"{sym['class_name']} {sym['confidence']:.2f}"
            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(image, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)
            
        cv2.imwrite('output/symbol_detection_result.png', image)
        print("Symbol detection result saved to 'output/symbol_detection_result.png'")
    ```

3.  **ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ê³¼ í†µí•©**:
    - `extract_measures.py` ë˜ëŠ” `scoreeye_gui.py`ì—ì„œ ë§ˆë”” ì´ë¯¸ì§€ë¥¼ ìƒì„±í•œ í›„, `SymbolDetector`ë¥¼ í˜¸ì¶œí•˜ì—¬ ê° ë§ˆë””ì˜ ê¸°í˜¸ë¥¼ ì¸ì‹í•˜ëŠ” ë¡œì§ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
    - ì¸ì‹ëœ ê¸°í˜¸ ì •ë³´(ìœ„ì¹˜, í´ë˜ìŠ¤)ì™€ ë§ˆë””ì˜ ë©”íƒ€ë°ì´í„°(`metadata.json`)ë¥¼ ê²°í•©í•˜ì—¬ MusicXML ìƒì„± ë“± í›„ì† ì‘ì—…ì„ ìœ„í•œ ê¸°ë°˜ì„ ë§ˆë ¨í•©ë‹ˆë‹¤.

---

### **ğŸ—“ï¸ ì˜ˆìƒ íƒ€ì„ë¼ì¸**

- **Week 1**:
  - [ ] í™˜ê²½ ì„¤ì • ë° ë°ì´í„° ë‹¤ìš´ë¡œë“œ (1ì¼)
  - [ ] `preprocess_deepscores.py` ê°œë°œ ë° í…ŒìŠ¤íŠ¸ (2-3ì¼)
  - [ ] ë°ì´í„°ì…‹ ë³€í™˜ ì™„ë£Œ ë° ìƒ˜í”Œ í™•ì¸ (1ì¼)
- **Week 2**:
  - [ ] `deepscores.yaml` ì‘ì„± ë° ì´ˆê¸° í…ŒìŠ¤íŠ¸ í•™ìŠµ (1ì¼)
  - [ ] ë³¸ í•™ìŠµ ì‹¤í–‰ ë° ëª¨ë‹ˆí„°ë§ (2-4ì¼, GPU ì„±ëŠ¥ì— ë”°ë¼ ë³€ë™)
- **Week 3**:
  - [ ] `symbol_detector.py` ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸ ê°œë°œ (1ì¼)
  - [ ] `ScoreEye` í”„ë¡œì íŠ¸ì— í†µí•© ë° í…ŒìŠ¤íŠ¸ (2ì¼)
  - [ ] ê²°ê³¼ ë¶„ì„ ë° ê°œì„  ë°©í–¥ ìˆ˜ë¦½ (1ì¼)

ì´ ê³„íšì„ ë”°ë¥´ë©´ ì²´ê³„ì ìœ¼ë¡œ ìŒí‘œ ì¸ì‹ ëª¨ë¸ì„ ê°œë°œí•˜ê³  í”„ë¡œì íŠ¸ì— ì„±ê³µì ìœ¼ë¡œ í†µí•©í•  ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.

---

### **ğŸ”§ êµ¬í˜„ ê³„íš ê°œì„  ì œì•ˆ**

#### **1. Phase 2 ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ë‹¨ê³„ ê°•í™”**

í˜„ì¬ ê³„íšì˜ `preprocess_deepscores.py`ëŠ” ë‹¨ìˆœ í¬ë§· ë³€í™˜ë§Œ ìˆ˜í–‰í•˜ë¯€ë¡œ, ë‹¤ìŒ ê²€ì¦ ë‹¨ê³„ë“¤ì„ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤:

**ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦**
```python
def validate_dataset_quality():
    """ë°ì´í„°ì…‹ í’ˆì§ˆ ê²€ì¦ í•¨ìˆ˜"""
    # 1. ì´ë¯¸ì§€-ë¼ë²¨ ë§¤ì¹­ í™•ì¸
    missing_pairs = check_image_label_pairs()
    
    # 2. ë°”ìš´ë”© ë°•ìŠ¤ ìœ íš¨ì„± ê²€ì‚¬
    invalid_bboxes = validate_bboxes()  # 0-1 ë²”ìœ„, ë„ˆë¹„/ë†’ì´ > 0
    
    # 3. í´ë˜ìŠ¤ ë¶„í¬ ë¶„ì„
    class_distribution = analyze_class_distribution()
    
    # 4. ì´ë¯¸ì§€ í’ˆì§ˆ í™•ì¸
    corrupted_images = detect_corrupted_images()
    
    # ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±
    generate_validation_report(missing_pairs, invalid_bboxes, class_distribution, corrupted_images)
```

**í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¶„ì„ ë° í•´ê²°**
```python
def analyze_class_imbalance():
    """
    í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¶„ì„ ë° í•´ê²°ì±… ì œì•ˆ
    - noteheadFullì´ 90%, dotì´ 1% ê°™ì€ ì‹¬ê°í•œ ë¶ˆê· í˜• ë°œê²¬
    - ì†Œìˆ˜ í´ë˜ìŠ¤ì— ëŒ€í•œ augmentation ì¦ê°€
    - weighted loss í•¨ìˆ˜ ì‚¬ìš© ê¶Œì¥
    - focal loss ì ìš© ê³ ë ¤
    """
    class_counts = count_annotations_per_class()
    imbalance_ratio = calculate_imbalance_ratio(class_counts)
    
    # ì‹œê°í™”
    plot_class_distribution(class_counts)
    
    # í•´ê²°ì±… ì œì•ˆ
    balancing_strategy = recommend_balancing_strategy(imbalance_ratio)
    return balancing_strategy
```

**ì–´ë…¸í…Œì´ì…˜ í’ˆì§ˆ ìƒ˜í”Œ ê²€ì‚¬**
```python
def visual_annotation_check():
    """
    ë¬´ì‘ìœ„ë¡œ 100ê°œ ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ì—¬ 
    ë°”ìš´ë”© ë°•ìŠ¤ê°€ ì‹¤ì œ ê¸°í˜¸ì™€ ì •í™•íˆ ë§¤ì¹­ë˜ëŠ”ì§€ ì‹œê°ì  í™•ì¸
    """
    sample_images = random.sample(all_images, 100)
    annotation_quality_scores = []
    
    for img in sample_images:
        quality_score = visualize_and_check_annotations(img)
        annotation_quality_scores.append(quality_score)
    
    # ìˆ˜ë™ ê²€í† ë¥¼ ìœ„í•œ HTML ë¦¬í¬íŠ¸ ìƒì„±
    generate_quality_check_report(sample_images, annotation_quality_scores)
```

#### **2. ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ ë©”íŠ¸ë¦­ ì²´ê³„ êµ¬ì¶•**

í˜„ì¬ ê³„íšì—ëŠ” ì„±ëŠ¥ í‰ê°€ ê¸°ì¤€ì´ ëª…ì‹œë˜ì§€ ì•Šì•„ ë‹¤ìŒ ë©”íŠ¸ë¦­ ì‹œìŠ¤í…œì´ í•„ìš”í•©ë‹ˆë‹¤:

**ê¸°ë³¸ Detection ë©”íŠ¸ë¦­**
```python
class OMRMetrics:
    """OMR íŠ¹í™” ì„±ëŠ¥ í‰ê°€ ë©”íŠ¸ë¦­"""
    
    def __init__(self):
        self.iou_thresholds = [0.3, 0.5, 0.7]  # OMRì€ 0.5ë³´ë‹¤ ë‚®ì€ thresholdë„ ì˜ë¯¸ìˆìŒ
        self.class_names = ['noteheadFull', 'noteheadHalf', 'stem', 'beam', 'dot', 
                           'gClef', 'fClef', 'restQuarter', 'restHalf']
        
    def evaluate_model(self, model, val_dataset):
        """ì¢…í•© ëª¨ë¸ ì„±ëŠ¥ í‰ê°€"""
        # 1. í‘œì¤€ COCO ë©”íŠ¸ë¦­
        mAP_30 = self.calculate_map(iou_threshold=0.3)
        mAP_50 = self.calculate_map(iou_threshold=0.5)
        mAP_75 = self.calculate_map(iou_threshold=0.75)
        
        # 2. í´ë˜ìŠ¤ë³„ ì •ë°€ë„/ì¬í˜„ìœ¨
        per_class_metrics = {}
        for class_name in self.class_names:
            precision, recall, f1 = self.calculate_precision_recall(class_name)
            per_class_metrics[class_name] = {
                'precision': precision,
                'recall': recall, 
                'f1_score': f1
            }
        
        return {
            'mAP@0.3': mAP_30,
            'mAP@0.5': mAP_50,
            'mAP@0.75': mAP_75,
            'per_class': per_class_metrics
        }
```

**OMR ì „ìš© ë©”íŠ¸ë¦­**
```python
def calculate_omr_specific_metrics():
    """ìŒì•… ê¸°ë³´ë²• íŠ¹ì„±ì„ ê³ ë ¤í•œ ì „ìš© ë©”íŠ¸ë¦­"""
    
    # 1. ìŒí‘œ êµ¬ì„±ìš”ì†Œ ì™„ì„±ë„ (Notehead + Stem ë§¤ì¹­ë¥ )
    note_completeness = measure_note_component_matching()
    
    # 2. ìˆ˜ì§ ì •ë ¬ ì •í™•ë„ (ê°™ì€ ì‹œê°„ì˜ ìŒí‘œë“¤ì´ ìˆ˜ì§ìœ¼ë¡œ ì •ë ¬ë˜ëŠ”ê°€)
    vertical_alignment_score = measure_vertical_alignment()
    
    # 3. ë§ˆë””ë³„ ê¸°í˜¸ ë°€ë„ ë¶„ì„ (ê³¼ë„í•œ false positive ê²€ì¶œ ë°©ì§€)
    symbols_per_measure = analyze_symbol_density()
    
    # 4. í´ë˜ìŠ¤ í˜¼ë™ ë§¤íŠ¸ë¦­ìŠ¤ (noteheadFull vs noteheadHalf êµ¬ë¶„ ì •í™•ë„)
    confusion_matrix = calculate_class_confusion()
    
    return {
        'note_completeness': note_completeness,
        'vertical_alignment': vertical_alignment_score,
        'symbol_density': symbols_per_measure,
        'class_confusion': confusion_matrix
    }
```

**ì‹¤ì œ ì‚¬ìš©ì„± ë©”íŠ¸ë¦­**
```python
def measure_practical_performance():
    """ì‹¤ì œ ScoreEye íŒŒì´í”„ë¼ì¸ì—ì„œì˜ ì„±ëŠ¥ ì¸¡ì •"""
    
    pipeline_metrics = {
        'processing_time_per_measure': [],      # ë§ˆë””ë‹¹ ì²˜ë¦¬ ì‹œê°„
        'memory_usage_peak': [],                # ìµœëŒ€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
        'gpu_utilization': [],                  # GPU í™œìš©ë¥ 
        'success_rate_on_real_scores': 0.0,    # ì‹¤ì œ ì•…ë³´ì—ì„œì˜ ì„±ê³µë¥ 
        'integration_compatibility': 0.0       # ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ê³¼ì˜ í˜¸í™˜ì„±
    }
    
    return pipeline_metrics
```

#### **3. ì‹¤íŒ¨ ì‚¬ë¡€ ë¶„ì„ì„ ìœ„í•œ ì‹œê°í™” ë„êµ¬**

ë””ë²„ê¹…ê³¼ ëª¨ë¸ ê°œì„ ì„ ìœ„í•œ ì²´ê³„ì ì¸ ì‹œê°í™” ì‹œìŠ¤í…œ:

**Detection ì‹¤íŒ¨ ë¶„ë¥˜ ë„êµ¬**
```python
class FailureAnalyzer:
    """ì‹¤íŒ¨ ì‚¬ë¡€ ìë™ ë¶„ë¥˜ ë° ë¶„ì„"""
    
    def __init__(self, model, test_dataset):
        self.model = model
        self.test_dataset = test_dataset
        self.failure_categories = {
            'false_positive': [],    # ì˜ëª» ê°ì§€ëœ ì˜ì—­
            'false_negative': [],    # ë†“ì¹œ ê¸°í˜¸ë“¤  
            'misclassification': [], # ì˜ëª» ë¶„ë¥˜ëœ ê¸°í˜¸ë“¤
            'bbox_inaccuracy': [],   # ìœ„ì¹˜ëŠ” ë§ì§€ë§Œ ë°•ìŠ¤ ë¶€ì •í™•
        }
    
    def categorize_failures(self):
        """ì‹¤íŒ¨ ì‚¬ë¡€ë¥¼ ìœ í˜•ë³„ë¡œ ìë™ ë¶„ë¥˜"""
        for image, ground_truth in self.test_dataset:
            predictions = self.model(image)
            failures = self.compare_predictions_gt(predictions, ground_truth)
            self.categorize_by_type(failures)
        
        return self.generate_failure_report()
```

**Interactive ì‹œê°í™” ëŒ€ì‹œë³´ë“œ**
```python
def create_failure_dashboard():
    """
    Streamlit ë˜ëŠ” Flask ê¸°ë°˜ ì›¹ ëŒ€ì‹œë³´ë“œ
    - ì‹¤íŒ¨ ì‚¬ë¡€ë¥¼ ì¹´í…Œê³ ë¦¬ë³„ë¡œ í•„í„°ë§
    - ê° ì‹¤íŒ¨ ì‚¬ë¡€ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ (confidence score, IoU ê°’ ë“±)
    - ê°œì„  ìš°ì„ ìˆœìœ„ ì œì•ˆ
    """
    
    dashboard_features = [
        'failure_heatmap',          # ì–´ë–¤ ìœ„ì¹˜ì—ì„œ ì‹¤íŒ¨ê°€ ë§ì´ ë°œìƒí•˜ëŠ”ê°€
        'class_confusion_matrix',   # ì–´ë–¤ í´ë˜ìŠ¤ ê°„ í˜¼ë™ì´ ë§ì€ê°€  
        'confidence_distribution',  # ë‚®ì€ confidenceì˜ ì •í™•í•œ detection vs ë†’ì€ confidenceì˜ false positive
        'scale_analysis',          # í¬ê¸°ë³„ detection ì„±ëŠ¥ ë¶„ì„
        'context_analysis'         # ì£¼ë³€ ê¸°í˜¸ì— ë”°ë¥¸ ì„±ëŠ¥ ì°¨ì´
    ]
    
    return dashboard_features
```

**ìë™ ê°œì„  ì œì•ˆ ì‹œìŠ¤í…œ**
```python
def generate_improvement_recommendations():
    """ì‹¤íŒ¨ ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ìë™ ê°œì„  ì œì•ˆ"""
    
    failure_analysis = analyze_all_failures()
    
    recommendations = {
        'data_augmentation': suggest_augmentation_strategies(failure_analysis),
        'hyperparameter_tuning': suggest_parameter_changes(failure_analysis), 
        'architecture_changes': suggest_model_modifications(failure_analysis),
        'post_processing': suggest_post_processing_rules(failure_analysis)
    }
    
    # ì˜ˆì‹œ: "noteheadHalf í´ë˜ìŠ¤ì˜ ì¬í˜„ìœ¨ì´ 65%ë¡œ ë‚®ìŠµë‹ˆë‹¤. 
    #       í•´ë‹¹ í´ë˜ìŠ¤ ì´ë¯¸ì§€ì— brightness augmentation ì¶”ê°€ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤."
    
    return recommendations
```

#### **4. ì ì§„ì  í´ë˜ìŠ¤ í™•ì¥ ì „ëµ**

ì´ˆê¸° 10ê°œ í´ë˜ìŠ¤ì—ì„œ ë‹¨ê³„ì ìœ¼ë¡œ í™•ì¥í•˜ëŠ” ì „ëµ:

```python
expansion_phases = {
    'phase_1': {
        'classes': ['noteheadFull', 'stem', 'gClef'],  # í•µì‹¬ 3ê°œë¡œ ì‹œì‘
        'target_mAP': 0.85,
        'duration': '3-4ì¼'
    },
    'phase_2': {
        'classes': ['restQuarter', 'beam', 'dot'],     # ê¸°ë³¸ ë¦¬ë“¬ ìš”ì†Œ ì¶”ê°€  
        'target_mAP': 0.80,
        'duration': '2-3ì¼'
    },
    'phase_3': {
        'classes': ['sharp', 'flat', 'natural'],       # ì„ì‹œí‘œ ì¶”ê°€
        'target_mAP': 0.75,
        'duration': '2ì¼'
    },
    'phase_4': {
        'classes': ['timeSig4_4', 'keySigFlat1'],      # ì¡°í‘œ/ë°•ìí‘œ ì¶”ê°€
        'target_mAP': 0.70,
        'duration': '2ì¼'
    }
}

def progressive_training_strategy():
    """ì ì§„ì  í•™ìŠµ ì „ëµ êµ¬í˜„"""
    for phase_name, phase_config in expansion_phases.items():
        print(f"Starting {phase_name}: {phase_config['classes']}")
        
        # ì´ì „ ë‹¨ê³„ ê°€ì¤‘ì¹˜ë¡œ ì´ˆê¸°í™”
        model = load_previous_phase_weights() if phase_name != 'phase_1' else 'yolov8s.pt'
        
        # í•´ë‹¹ ë‹¨ê³„ í´ë˜ìŠ¤ë§Œìœ¼ë¡œ í•™ìŠµ
        train_model(model, phase_config['classes'], phase_config['target_mAP'])
```

#### **5. ë„ë©”ì¸ ì ì‘ ì „ëµ**

DeepScoresëŠ” í•©ì„± ë°ì´í„°ì´ë¯€ë¡œ ì‹¤ì œ ìŠ¤ìº” ì•…ë³´ì™€ì˜ ë„ë©”ì¸ ì°¨ì´ í•´ê²°:

```python
def domain_adaptation_pipeline():
    """ì‹¤ì œ ì•…ë³´ ì´ë¯¸ì§€ì— ëŒ€í•œ ë„ë©”ì¸ ì ì‘"""
    
    adaptation_stages = [
        {
            'name': 'synthetic_pretraining',
            'data': 'DeepScores í•©ì„± ë°ì´í„°',
            'epochs': 50,
            'description': 'ê¸°ë³¸ íŒ¨í„´ í•™ìŠµ'
        },
        {
            'name': 'noise_simulation',  
            'data': 'DeepScores + ë…¸ì´ì¦ˆ/ê¸°ìš¸ì–´ì§ ì‹œë®¬ë ˆì´ì…˜',
            'epochs': 20,
            'description': 'ì‹¤ì œ ìŠ¤ìº” í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜'
        },
        {
            'name': 'real_data_finetuning',
            'data': 'ScoreEye ì‹¤ì œ ì²˜ë¦¬ ì´ë¯¸ì§€ (ìˆ˜ë™ ë¼ë²¨ë§)',
            'epochs': 10,
            'description': 'ì‹¤ì œ ë°ì´í„° ë¯¸ì„¸ì¡°ì •'
        }
    ]
    
    # ê° ë‹¨ê³„ë³„ ìˆœì°¨ í•™ìŠµ
    for stage in adaptation_stages:
        fine_tune_model(stage)
```

#### **6. ë©”ëª¨ë¦¬ ìµœì í™” ë°©ì•ˆ**

1024px ì´ë¯¸ì§€ ì²˜ë¦¬ë¥¼ ìœ„í•œ ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê°œì„ :

```python
optimization_strategies = {
    'multi_scale_training': {
        'strategy': 'YOLOv8s with 640px ê¸°ë³¸ í•™ìŠµ â†’ 1024px fine-tuning',
        'memory_savings': '60%',
        'performance_impact': 'ìµœì†Œ (<5%)'
    },
    'gradient_accumulation': {
        'strategy': 'batch_size=4 Ã— accumulation=4 = effective_batch_size=16',
        'memory_savings': '75%',
        'training_time_impact': '+10%'
    },
    'mixed_precision': {
        'strategy': 'FP16 training',
        'memory_savings': '50%',
        'speedup': '2x'
    },
    'tiled_inference': {
        'strategy': 'í° ì´ë¯¸ì§€ë¥¼ ê²¹ì¹˜ëŠ” íƒ€ì¼ë¡œ ë¶„í• í•˜ì—¬ ì²˜ë¦¬',
        'memory_savings': '80%',
        'accuracy_impact': 'ìµœì†Œ (overlap ì²˜ë¦¬ ì‹œ)'
    }
}

def implement_memory_optimization():
    """ë©”ëª¨ë¦¬ ìµœì í™” êµ¬í˜„"""
    
    # 1. ë™ì  ë°°ì¹˜ í¬ê¸° ì¡°ì •
    def adjust_batch_size_based_on_gpu():
        gpu_memory = get_gpu_memory()
        if gpu_memory < 8:  # 8GB ë¯¸ë§Œ
            return 4
        elif gpu_memory < 16:  # 16GB ë¯¸ë§Œ
            return 8
        else:
            return 16
    
    # 2. ì ì§„ì  ì´ë¯¸ì§€ í¬ê¸° ì¦ê°€
    def progressive_image_scaling():
        training_phases = [
            {'epochs': 30, 'img_size': 640},
            {'epochs': 20, 'img_size': 832}, 
            {'epochs': 10, 'img_size': 1024}
        ]
        return training_phases
```

#### **7. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ì¶”ì **

```python
def create_comprehensive_monitoring():
    """í¬ê´„ì ì¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œ"""
    
    # Weights & Biases ì—°ë™
    wandb.init(project="scoreeye-yolov8", 
               config={
                   "dataset": "DeepScores-v2-subset",
                   "model": "YOLOv8s",
                   "classes": 10
               })
    
    # ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ë©”íŠ¸ë¦­
    monitoring_metrics = [
        'training_loss',
        'validation_mAP', 
        'per_class_precision',
        'per_class_recall',
        'gpu_memory_usage',
        'training_speed',
        'sample_predictions'  # ë§¤ epoch ìƒ˜í”Œ ì´ë¯¸ì§€ ê²°ê³¼
    ]
    
    # ì¡°ê¸° ì¢…ë£Œ ì¡°ê±´
    early_stopping_config = {
        'monitor': 'val_mAP',
        'patience': 15,
        'min_delta': 0.001,
        'restore_best_weights': True
    }
```

#### **8. ìˆ˜ì •ëœ íƒ€ì„ë¼ì¸**

ê°œì„  ì œì•ˆì„ ë°˜ì˜í•œ í˜„ì‹¤ì ì¸ íƒ€ì„ë¼ì¸:

- **Week 1-2**:
  - [ ] í™˜ê²½ ì„¤ì • ë° DeepScores ë°ì´í„° ë‹¤ìš´ë¡œë“œ (2ì¼)
  - [ ] **ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì‹œìŠ¤í…œ êµ¬ì¶•** (2ì¼) â­ ì‹ ê·œ
  - [ ] `preprocess_deepscores.py` ê°œë°œ ë° í…ŒìŠ¤íŠ¸ (3ì¼)
  - [ ] **í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¶„ì„ ë° í•´ê²°ë°©ì•ˆ ìˆ˜ë¦½** (1ì¼) â­ ì‹ ê·œ

- **Week 3-4**:
  - [ ] **ì„±ëŠ¥ í‰ê°€ ë©”íŠ¸ë¦­ ì‹œìŠ¤í…œ êµ¬í˜„** (2ì¼) â­ ì‹ ê·œ
  - [ ] Phase 1 í´ë˜ìŠ¤ (3ê°œ) í•™ìŠµ ë° í‰ê°€ (3ì¼)
  - [ ] **ì‹¤íŒ¨ ì‚¬ë¡€ ë¶„ì„ ë„êµ¬ êµ¬ì¶•** (2ì¼) â­ ì‹ ê·œ
  - [ ] Phase 2 í´ë˜ìŠ¤ í™•ì¥ ë° í•™ìŠµ (3ì¼)

- **Week 5-6**:
  - [ ] **ë„ë©”ì¸ ì ì‘ íŒŒì´í”„ë¼ì¸ êµ¬í˜„** (3ì¼) â­ ì‹ ê·œ
  - [ ] `symbol_detector.py` ìµœì í™” ë²„ì „ ê°œë°œ (2ì¼)
  - [ ] ScoreEye í”„ë¡œì íŠ¸ í†µí•© ë° ì¢…í•© í…ŒìŠ¤íŠ¸ (3ì¼)
  - [ ] **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ì™„ì„±** (2ì¼) â­ ì‹ ê·œ

**ì˜ˆìƒ ì´ ì†Œìš” ê¸°ê°„**: 6ì£¼ (ê¸°ì¡´ 3ì£¼ â†’ 6ì£¼ë¡œ í˜„ì‹¤ì  ì¡°ì •)

ì´ëŸ¬í•œ ê°œì„ ì‚¬í•­ë“¤ì´ ì¶”ê°€ë˜ë©´ ì›ë˜ ê³„íšì˜ ì„±ê³µë¥ ê³¼ ì‹¤ìš©ì„±ì´ í¬ê²Œ í–¥ìƒë˜ë©°, ì‹¤ì œ í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì•ˆì •ì ìœ¼ë¡œ ë™ì‘í•˜ëŠ” ëª¨ë¸ì„ êµ¬ì¶•í•  ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.
