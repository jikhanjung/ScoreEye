# 최종 OMR 실행 계획: 기호 감지, 후처리 및 품질 관리

**작성일**: 2025년 7월 22일
**문서 목적**: 객체 감지 모델링, 음높이 결정 후처리, 데이터 품질 관리를 포함한 포괄적인 OMR(Optical Music Recognition) 시스템 구축 실행 계획

---

## 🎯 최종 목표

1.  악보 이미지에서 **음표, 쉼표, 음자리표 등 핵심 음악 기호의 위치와 종류를 95% 이상의 정확도로 자동 식별**한다.
2.  인식된 기호 정보를 조합하여 **음높이(pitch)와 박자(rhythm)를 포함한 구조화된 데이터로 변환**한다.
3.  향후 MusicXML과 같은 표준 디지털 악보 형식으로 출력할 수 있는 **강력하고 확장 가능한 기반**을 마련한다.

---

## 🚀 핵심 전략: 모듈화된 파이프라인 접근법

전체 OMR 프로세스를 명확하게 정의된 단계별 모듈로 구성하여 개발, 테스트, 유지보수의 효율성을 극대화한다.

**`페이지 → 시스템 그룹 → 마디 → [기호 감지 → 후처리] → 구조화된 데이터`**

---

## 🔧 상세 실행 계획

### **Phase 1: 고품질 데이터셋 구축 (Dataset Generation & Labeling)**

#### 1.1. 마디 단위 이미지 및 메타데이터 생성
- **입력**: 원본 악보 PDF 파일.
- **도구**: `extract_measures.py` 스크립트.
- **프로세스**:
    1.  스크립트를 실행하여 PDF의 각 페이지를 처리.
    2.  페이지별로 폴더 생성 (`output/measures/page_01/`).
    3.  폴더 내에 개별 마디 이미지(`01_001.png`)와 모든 마디의 메타데이터를 담은 `metadata.json` 파일을 생성.
- **핵심 산출물**: 라벨링을 위한 정제된 마디 이미지와 후처리에 필수적인 위치 정보(BBox, 오선 좌표)가 담긴 JSON 파일.

#### 1.2. 점진적 클래스 라벨링 및 품질 관리
- **라벨링 도구**: **Roboflow** 사용을 강력히 권장 (데이터 관리, 증강, 포맷 변환 통합).
- **전략**: **점진적 클래스 확장 전략**을 채택하여 빠르고 반복적인 개발을 추구한다.
    - **Level 1 (핵심 음/쉼표)**: `notehead-full`, `notehead-half`, `quarter-rest`, `half-rest`, `whole-rest`.
    - **Level 2 (음표 구성요소)**: `stem`, `beam`, `g-clef`, `f-clef`.
    - **Level 3 (변화표 및 기타)**: `dot`, `sharp`, `flat`, 추가 쉼표 등.
- **품질 관리 (매우 중요)**:
    - **교차 검증**: 2명 이상이 독립적으로 라벨링 후 불일치 항목 검토.
    - **자동 검증 스크립트**: 음악적 규칙(예: 음표머리는 기둥과 연결)에 기반한 라벨링 오류 자동 검출.
    - **시각화 검토**: 라벨링된 BBox를 이미지에 오버레이하여 시각적으로 신속하게 검토.

### **Phase 2: YOLO 기반 모델 학습 (Model Training)**

- **모델**: **YOLOv8** 아키텍처 사용.
- **학습 방식**: **전이 학습(Transfer Learning)**. COCO 사전 학습 모델을 악보 데이터셋으로 Fine-tuning.
- **프로세스**:
    1.  **데이터 분할**: Training / Validation / Test 세트 (80/10/10)로 분할.
    2.  **데이터 증강**: Roboflow 또는 Albumentations 라이브러리를 활용하여 밝기, 회전, 노이즈 등 적용.
    3.  **모델 학습**: PyTorch 환경에서 YOLOv8 학습 스크립트 실행. mAP@0.5를 핵심 성능 지표로 모니터링.
    4.  **모델 저장**: Validation 성능이 가장 좋은 모델 가중치(`best.pt`)를 최종 모델로 저장.

### **Phase 3: 추론 및 지능형 후처리 (Inference & Intelligent Post-processing)**

- **추론 (Inference)**:
    1.  저장된 `best.pt` 모델을 로드.
    2.  입력된 악보에 대해 Phase 1.1과 동일하게 마디 이미지를 실시간으로 생성.
    3.  생성된 각 마디 이미지에 대해 YOLO 모델을 적용하여 기호의 `(클래스, BBox)` 목록을 예측.

- **지능형 후처리 (Post-processing)**:
    1.  **좌표 변환**: 예측된 기호의 **상대 BBox(마디 내 좌표)**를 `metadata.json`의 정보를 이용해 **페이지의 절대 BBox**로 변환.
    2.  **음높이 결정**: `determine_pitch` 함수를 구현하여 음표 머리(notehead)의 절대 좌표와 오선 정보를 바탕으로 정확한 음높이(예: 'G4')를 계산. 이 함수는 반드시 음자리표(clef) 정보를 고려해야 함.
        ```python
        def determine_pitch(notehead_bbox, staff_lines, clef_type='treble'):
            # ... (devlog/20250722_02_object_detection_plan.md의 로직 기반)
        ```
    3.  **음악적 관계 재구성**: 개별 기호들을 의미 있는 단위로 재조립.
        - 음표머리(notehead)와 기둥(stem), 빔(beam)을 연결하여 하나의 완전한 음표 객체로 그룹화.
        - 음표와 바로 앞의 임시표(sharp, flat)를 연결.
    4.  **최종 데이터 구조화**: 모든 정보를 종합하여 페이지별로 구조화된 데이터를 생성. (향후 MusicXML 변환을 위한 중간 단계)

---

## 📊 성공 지표 및 검증

1.  **데이터셋 품질**: 자동 검증 스크립트를 통해 라벨링 오류율 1% 미만 달성.
2.  **모델 성능**: Level 1 클래스에 대해 Test set **mAP@0.5 > 95%** 달성.
3.  **End-to-End 정확도**: `La Gazza ladra Overture` 1페이지의 모든 음표와 쉼표를 95% 이상 정확하게 인식하고, 음높이를 98% 이상 정확하게 결정.
4.  **처리 속도**: 페이지당 전체 파이프라인(마디 추출 ~ 최종 데이터 생성)을 10초 이내에 완료.

---

## 🗓️ 예상 마일스톤

- **Week 1: 데이터셋 구축 및 초기 라벨링**
  - [x] `extract_measures.py` 스크립트 완성 및 테스트.
  - [ ] 샘플 PDF 3개 이상에 대해 마디 이미지 데이터셋 생성.
  - [ ] Roboflow 프로젝트 생성 및 **Level 1 클래스**에 대해 최소 100개 마디 이미지 라벨링 완료.
  - [ ] 데이터 품질 검증 스크립트 초안 작성.

- **Week 2-3: 핵심 모델 학습 및 프로토타이핑**
  - [ ] YOLOv8 학습 환경 구축 및 Level 1 데이터로 1차 모델 학습.
  - [ ] 추론 및 후처리 파이프라인 프로토타입 개발 (`determine_pitch` 함수 포함).
  - [ ] 초기 모델의 성능을 분석하고 개선 방향 수립 (데이터 증강, 하이퍼파라미터 튜닝).

- **Week 4-5: 모델 고도화 및 기능 확장**
  - [ ] **Level 2, 3 클래스**에 대한 라벨링 확장 및 모델 재학습.
  - [ ] 음악적 관계 재구성(음표-기둥 연결 등) 로직 구현.
  - [ ] 전체 파이프라인 통합 테스트 및 성능 최적화.

- **Week 6: 최종 평가 및 문서화**
  - [ ] 새로운 테스트 악보에 대한 End-to-End 성능 최종 평가.
  - [ ] 프로젝트 결과 및 사용법 문서화.
