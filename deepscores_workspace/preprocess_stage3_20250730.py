#!/usr/bin/env python3
"""
Stage 3 DeepScores ë°ì´í„° ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸
ì‘ì„±ì¼: 2025-07-30
ëª©ì : Stage 2ì˜ í´ë˜ìŠ¤ ID ë§¤í•‘ ì˜¤ë¥˜ ìˆ˜ì • - clefG í¬í•¨, beam/tie/slur ì •í™•íˆ ì œì™¸
ê°œì„ ì‚¬í•­:
- clefG (ID: 6) ë°˜ë“œì‹œ í¬í•¨
- beam (ID: 122), tie (ID: 123), slur (ID: 121) ì •í™•íˆ ì œì™¸
- í´ë˜ìŠ¤ ì´ë¦„ìœ¼ë¡œ ìµœì¢… ê²€ì¦ ë‹¨ê³„ ì¶”ê°€
"""

import json
import os
import cv2
import numpy as np
from pathlib import Path
import random
from collections import defaultdict
import yaml
from tqdm import tqdm
import shutil
from datetime import datetime

class Stage3Preprocessor:
    def __init__(self, config_file='stage3_preprocess_config.json'):
        # Stage 1 configë¥¼ ê¸°ë°˜ìœ¼ë¡œ ìˆ˜ì •
        if not Path(config_file).exists():
            # Stage 1 configë¥¼ ë³µì‚¬í•˜ì—¬ ìˆ˜ì •
            with open('stage1_preprocess_config.json', 'r') as f:
                self.config = json.load(f)
            self.config['target_path'] = './data_stage3_20250730'
            self.config['image_size'] = 1024  # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ ì¶•ì†Œ
        else:
            with open(config_file, 'r') as f:
                self.config = json.load(f)
        
        self.source_path = Path(self.config['source_path'])
        self.target_path = Path(self.config['target_path'])
        
        # ì œì™¸í•  í´ë˜ìŠ¤ ID (cat_id ê¸°ì¤€) - Stage 2 ì˜¤ë¥˜ ìˆ˜ì • + ì‘ì€ ì ë“¤ ì œì™¸
        self.excluded_classes = {
            '42',   # stem (ì¤„ê¸°) - ì–‡ê³  ê²€ì¶œ ì–´ë ¤ì›€
            '2',    # ledgerLine (ë§ì¤„) - ì–‡ê³  ê²€ì¶œ ì–´ë ¤ì›€
            '122',  # beam (ë³´) - ë³µì¡í•œ ì—°ê²°ì„ 
            '123',  # tie (ë¶™ì„ì¤„) - ê³¡ì„ ì´ê³  ì–‡ìŒ
            '121',  # slur (ì´ìŒì¤„) - ê³¡ì„ ì´ê³  ì–‡ìŒ
            '41',   # augmentationDot - ë§¤ìš° ì‘ì€ ì  (1-2í”½ì…€)
            '73',   # articStaccatoAbove - ë§¤ìš° ì‘ì€ ì 
            '74',   # articStaccatoBelow - ë§¤ìš° ì‘ì€ ì 
            '3'     # repeatDot - ì‘ì€ ì , recall ë‚®ìŒ
        }
        
        # ë¡œê·¸ ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ë¨¼ì €)
        self.log_messages = []
        
        # ì œì™¸í•  í´ë˜ìŠ¤ë¥¼ ëº€ ë‚˜ë¨¸ì§€ë§Œ ì„ íƒ
        original_selected = set(str(cls_id) for cls_id in self.config['selected_classes'])
        self.selected_classes = original_selected - self.excluded_classes
        
        # í´ë˜ìŠ¤ ë§¤í•‘ ì¬ìƒì„±
        self.regenerate_class_mapping()
        
        # í´ë˜ìŠ¤ ì´ë¦„ ê²€ì¦ (Stage 3 ì‹ ê·œ ê¸°ëŠ¥)
        self.verify_class_selection()
        
        self.image_size = self.config['image_size']
        self.sample_ratio = self.config['sample_ratio']
        self.max_images = self.config['max_images']
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        self.setup_directories()
        
        # ë¡œê·¸ íŒŒì¼ ê²½ë¡œ ì„¤ì • (ë””ë ‰í† ë¦¬ ìƒì„± í›„)
        self.log_file = self.target_path / f'preprocessing_log_{datetime.now().strftime("%Y%m%d_%H%M%S")}.txt'
    
    def regenerate_class_mapping(self):
        """ì œì™¸ëœ í´ë˜ìŠ¤ë¥¼ ëº€ ìƒˆë¡œìš´ í´ë˜ìŠ¤ ë§¤í•‘ ìƒì„±"""
        sorted_classes = sorted(list(self.selected_classes), key=int)
        self.class_mapping = {cls_id: idx for idx, cls_id in enumerate(sorted_classes)}
        
        print(f"ğŸ“Š ì„ íƒëœ í´ë˜ìŠ¤ ìˆ˜: {len(self.selected_classes)}ê°œ (ì›ë˜ {len(self.config['selected_classes'])}ê°œì—ì„œ {len(self.excluded_classes)}ê°œ ì œì™¸)")
        self.log(f"Selected classes: {len(self.selected_classes)}, Excluded: {len(self.excluded_classes)} (including small dots)")
    
    def verify_class_selection(self):
        """í´ë˜ìŠ¤ ì„ íƒì´ ì˜¬ë°”ë¥¸ì§€ ì´ë¦„ìœ¼ë¡œ ê²€ì¦ (Stage 3 ì‹ ê·œ ê¸°ëŠ¥)"""
        self.log("ğŸ” í´ë˜ìŠ¤ ê²€ì¦ ì‹œì‘...")
        
        # stage1_classes.jsonì—ì„œ í´ë˜ìŠ¤ ì •ë³´ ë¡œë“œ
        with open('stage1_classes.json', 'r') as f:
            stage1_info = json.load(f)
        
        # ID -> ì´ë¦„ ë§¤í•‘ ìƒì„±
        id_to_name = {}
        for cls in stage1_info['classes']:
            id_to_name[str(cls['id'])] = cls['name']
        
        # ì œì™¸ëœ í´ë˜ìŠ¤ ê²€ì¦
        self.log("âŒ ì œì™¸ëœ í´ë˜ìŠ¤:")
        excluded_names = []
        for class_id in self.excluded_classes:
            class_name = id_to_name.get(class_id, f"Unknown_{class_id}")
            excluded_names.append(class_name)
            self.log(f"   ID {class_id}: {class_name}")
        
        # í¬í•¨ëœ ì¤‘ìš” í´ë˜ìŠ¤ í™•ì¸
        self.log("âœ… í¬í•¨ëœ ì¤‘ìš” í´ë˜ìŠ¤:")
        critical_classes = ['clefG', 'clefF', 'clefCAlto', 'noteheadBlack', 'staff']
        for critical in critical_classes:
            found = False
            for class_id in self.selected_classes:
                class_name = id_to_name.get(class_id, "Unknown")
                if critical.lower() in class_name.lower():
                    self.log(f"   âœ“ {class_name} (ID: {class_id})")
                    found = True
                    break
            if not found:
                self.log(f"   âš ï¸  {critical} - ì°¾ì„ ìˆ˜ ì—†ìŒ")
        
        # ì¹˜ëª…ì  ì˜¤ë¥˜ ê²€ì‚¬
        if '6' not in self.selected_classes:
            raise ValueError("âŒ CRITICAL: clefG (ID: 6)ê°€ ì œì™¸ë˜ì—ˆìŠµë‹ˆë‹¤! ì´ëŠ” ì¹˜ëª…ì  ì˜¤ë¥˜ì…ë‹ˆë‹¤.")
        else:
            self.log("âœ… clefG (ID: 6) ì •ìƒ í¬í•¨ í™•ì¸")
        
        # ì˜ëª» í¬í•¨ëœ ì–´ë ¤ìš´ í´ë˜ìŠ¤ ê²€ì‚¬
        problematic_in_selection = []
        for class_id in self.selected_classes:
            class_name = id_to_name.get(class_id, "Unknown")
            if any(difficult in class_name.lower() for difficult in ['beam', 'tie', 'slur']):
                problematic_in_selection.append(f"{class_name} (ID: {class_id})")
        
        if problematic_in_selection:
            self.log("âš ï¸  ì–´ë ¤ìš´ í´ë˜ìŠ¤ê°€ ì—¬ì „íˆ í¬í•¨ë¨:")
            for cls in problematic_in_selection:
                self.log(f"   - {cls}")
        else:
            self.log("âœ… beam, tie, slur ì •ìƒ ì œì™¸ í™•ì¸")
        
        self.log(f"âœ… í´ë˜ìŠ¤ ê²€ì¦ ì™„ë£Œ - ì´ {len(self.selected_classes)}ê°œ í´ë˜ìŠ¤")
    
    def log(self, message):
        """ë¡œê·¸ ë©”ì‹œì§€ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        log_entry = f"[{timestamp}] {message}"
        self.log_messages.append(log_entry)
        print(f"ğŸ“ {message}")
    
    def save_logs(self):
        """ë¡œê·¸ íŒŒì¼ ì €ì¥"""
        with open(self.log_file, 'w') as f:
            f.write('\n'.join(self.log_messages))
    
    def setup_directories(self):
        """ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±"""
        dirs = [
            'images/train',
            'images/val',
            'labels/train',
            'labels/val'
        ]
        
        for dir_name in dirs:
            (self.target_path / dir_name).mkdir(parents=True, exist_ok=True)
        
        self.log(f"Output directory created: {self.target_path}")
    
    def load_annotations(self, json_file):
        """JSON ì–´ë…¸í…Œì´ì…˜ ë¡œë“œ ë° í•„í„°ë§"""
        self.log(f"Loading annotations from: {json_file}")
        
        with open(json_file, 'r') as f:
            data = json.load(f)
        
        # ì¹´í…Œê³ ë¦¬ ì •ë³´
        categories = data['categories']
        images = data['images']
        annotations = data['annotations']
        
        # í•„í„°ë§ëœ ì–´ë…¸í…Œì´ì…˜ë§Œ ìˆ˜ì§‘
        filtered_annotations = defaultdict(list)
        annotation_count = 0
        excluded_count = 0
        
        # DeepScoresëŠ” annotationsë„ dict í˜•íƒœ
        if isinstance(annotations, dict):
            for ann_id, ann in annotations.items():
                cat_id = ann.get('cat_id')
                if cat_id:
                    # cat_idê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²« ë²ˆì§¸ ìš”ì†Œ ì‚¬ìš©
                    if isinstance(cat_id, list):
                        cat_id = cat_id[0] if cat_id else None
                    
                    if cat_id:
                        if cat_id in self.excluded_classes:
                            excluded_count += 1
                            continue
                        
                        if cat_id in self.selected_classes:
                            # DeepScoresëŠ” img_idë¥¼ ì‚¬ìš©
                            image_id = ann.get('img_id') or ann.get('image_id')
                            # DeepScoresëŠ” a_bboxë¥¼ ì‚¬ìš© (axis-aligned bbox)
                            bbox = ann.get('a_bbox') or ann.get('bbox', [0, 0, 1, 1])
                            
                            if image_id and bbox:
                                filtered_annotations[image_id].append({
                                    'cat_id': cat_id,
                                    'bbox': bbox,
                                    'area': ann.get('area', 1)
                                })
                                annotation_count += 1
        
        self.log(f"Filtering complete: {annotation_count:,d} annotations kept, {excluded_count:,d} excluded, {len(filtered_annotations):,d} images")
        return images, filtered_annotations, categories
    
    def convert_bbox_to_yolo(self, bbox, img_width, img_height):
        """DeepScores bboxë¥¼ YOLO í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        DeepScoresì˜ a_bboxëŠ” [x1, y1, x2, y2] í˜•ì‹
        """
        x1, y1, x2, y2 = bbox
        
        # width, height ê³„ì‚°
        width = abs(x2 - x1)
        height = abs(y2 - y1)
        
        # ì¤‘ì‹¬ì  ì¢Œí‘œ ê³„ì‚°
        center_x = (x1 + x2) / 2
        center_y = (y1 + y2) / 2
        
        # ì •ê·œí™”
        center_x /= img_width
        center_y /= img_height
        width /= img_width
        height /= img_height
        
        # ì¢Œí‘œê°€ 0-1 ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ì§€ ì•Šë„ë¡ í´ë¦¬í•‘
        center_x = max(0.0, min(1.0, center_x))
        center_y = max(0.0, min(1.0, center_y))
        width = max(0.0, min(1.0, width))
        height = max(0.0, min(1.0, height))
        
        return [center_x, center_y, width, height]
    
    def process_image(self, image_path, annotations, output_image_path, output_label_path):
        """ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬"""
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(str(image_path))
        if image is None:
            return False
        
        orig_height, orig_width = image.shape[:2]
        
        # ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ (ì •ì‚¬ê°í˜•ìœ¼ë¡œ)
        if orig_width != self.image_size or orig_height != self.image_size:
            # ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ íŒ¨ë”© ì¶”ê°€
            scale = self.image_size / max(orig_width, orig_height)
            new_width = int(orig_width * scale)
            new_height = int(orig_height * scale)
            
            # ë¦¬ì‚¬ì´ì¦ˆ
            resized = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)
            
            # íŒ¨ë”© ì¶”ê°€ (ê°€ìš´ë° ì •ë ¬)
            pad_x = (self.image_size - new_width) // 2
            pad_y = (self.image_size - new_height) // 2
            
            processed_image = np.full((self.image_size, self.image_size, 3), 255, dtype=np.uint8)
            processed_image[pad_y:pad_y+new_height, pad_x:pad_x+new_width] = resized
        else:
            processed_image = image.copy()
            scale = 1.0
            pad_x = pad_y = 0
        
        # ì´ë¯¸ì§€ ì €ì¥
        cv2.imwrite(str(output_image_path), processed_image)
        
        # ë¼ë²¨ ë³€í™˜ ë° ì €ì¥
        yolo_labels = []
        for ann in annotations:
            cat_id = ann['cat_id']
            bbox = ann['bbox']
            
            # ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ìƒˆë¡œìš´ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ê²Œ ì¡°ì •
            # DeepScores bboxëŠ” [x1, y1, x2, y2] í˜•ì‹
            x1, y1, x2, y2 = bbox
            
            # ì›ë³¸ ì´ë¯¸ì§€ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ëŠ” ë°”ìš´ë”© ë°•ìŠ¤ í•„í„°ë§
            if (x1 < 0 or y1 < 0 or x2 > orig_width or y2 > orig_height or
                x1 >= x2 or y1 >= y2):
                continue
            
            # ìŠ¤ì¼€ì¼ë§ ì ìš©
            x1_scaled = x1 * scale
            y1_scaled = y1 * scale
            x2_scaled = x2 * scale
            y2_scaled = y2 * scale
            
            # íŒ¨ë”© ì˜¤í”„ì…‹ ì ìš©
            x1_final = x1_scaled + pad_x
            y1_final = y1_scaled + pad_y
            x2_final = x2_scaled + pad_x
            y2_final = y2_scaled + pad_y
            
            # ë³€í™˜ëœ ì´ë¯¸ì§€ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ëŠ” ë°”ìš´ë”© ë°•ìŠ¤ í•„í„°ë§
            if (x1_final < 0 or y1_final < 0 or 
                x2_final > self.image_size or y2_final > self.image_size):
                continue
            
            # ë„ˆë¬´ ì‘ì€ ë°”ìš´ë”© ë°•ìŠ¤ í•„í„°ë§ (1í”½ì…€ ì´í•˜)
            width_final = x2_final - x1_final
            height_final = y2_final - y1_final
            if width_final < 1 or height_final < 1:
                continue
            
            # YOLO í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            yolo_bbox = self.convert_bbox_to_yolo([x1_final, y1_final, x2_final, y2_final], 
                                                 self.image_size, self.image_size)
            
            # ì¶”ê°€ ê²€ì¦: ëª¨ë“  ì¢Œí‘œê°€ ìœ íš¨í•œ ë²”ìœ„ì¸ì§€ í™•ì¸
            if all(0.0 <= coord <= 1.0 for coord in yolo_bbox):
                # í´ë˜ìŠ¤ ID ë§¤í•‘ (ë¬¸ìì—´ë¡œ ë³€í™˜)
                cat_id_str = str(cat_id)
                if cat_id_str in self.class_mapping:
                    class_id = self.class_mapping[cat_id_str]
                    yolo_labels.append(f"{class_id} {' '.join(map(str, yolo_bbox))}")
        
        # ë¼ë²¨ íŒŒì¼ ì €ì¥
        if yolo_labels:
            with open(output_label_path, 'w') as f:
                f.write('\n'.join(yolo_labels))
        else:
            # ë¹ˆ ë¼ë²¨ íŒŒì¼ ìƒì„±
            output_label_path.touch()
        
        return True
    
    def process_split(self, json_file, split_name, max_images_per_split):
        """ë°ì´í„° ë¶„í•  ì²˜ë¦¬"""
        self.log(f"Processing {split_name} split...")
        
        # ì–´ë…¸í…Œì´ì…˜ ë¡œë“œ
        images, filtered_annotations, categories = self.load_annotations(json_file)
        
        # ì´ë¯¸ì§€ ìƒ˜í”Œë§
        image_list = list(filtered_annotations.keys())
        if len(image_list) > max_images_per_split:
            image_list = random.sample(image_list, max_images_per_split)
        
        self.log(f"Images to process: {len(image_list):,d}")
        
        # ì¶œë ¥ ê²½ë¡œ ì„¤ì •
        image_output_dir = self.target_path / 'images' / split_name
        label_output_dir = self.target_path / 'labels' / split_name
        
        processed_count = 0
        skipped_count = 0
        
        # ì´ë¯¸ì§€ ì²˜ë¦¬
        for image_id in tqdm(image_list, desc=f"Processing {split_name}"):
            # ì´ë¯¸ì§€ ì •ë³´ ì°¾ê¸° (DeepScoresëŠ” ë¬¸ìì—´ í‚¤ ì‚¬ìš©)
            image_info = None
            if isinstance(images, dict):
                # ë¬¸ìì—´ê³¼ ì •ìˆ˜ ë‘˜ ë‹¤ ì‹œë„
                image_info = images.get(str(image_id)) or images.get(image_id)
            else:
                for img in images:
                    if img.get('id') == image_id or str(img.get('id')) == str(image_id):
                        image_info = img
                        break
            
            if not image_info:
                skipped_count += 1
                continue
            
            # íŒŒì¼ ê²½ë¡œ
            filename = image_info.get('filename') or image_info.get('file_name', f"{image_id}.png")
            image_path = self.source_path / 'images' / filename
            
            if not image_path.exists():
                skipped_count += 1
                continue
            
            # ì¶œë ¥ ê²½ë¡œ
            output_image_path = image_output_dir / filename
            output_label_path = label_output_dir / (Path(filename).stem + '.txt')
            
            # ì´ë¯¸ì§€ ì²˜ë¦¬
            if self.process_image(image_path, filtered_annotations[image_id], 
                                 output_image_path, output_label_path):
                processed_count += 1
            else:
                skipped_count += 1
        
        self.log(f"{split_name} complete: {processed_count:,d} processed, {skipped_count:,d} skipped")
        return processed_count
    
    def create_yaml_config(self):
        """YOLO í•™ìŠµì„ ìœ„í•œ YAML ì„¤ì • íŒŒì¼ ìƒì„±"""
        # í´ë˜ìŠ¤ ì´ë¦„ ë¡œë“œ
        with open('stage1_classes.json', 'r') as f:
            stage1_info = json.load(f)
        
        # í´ë˜ìŠ¤ ID -> ì´ë¦„ ë§¤í•‘ ìƒì„±
        id_to_name = {}
        for cls in stage1_info['classes']:
            if str(cls['id']) not in self.excluded_classes:
                id_to_name[str(cls['id'])] = cls['name']
        
        # ìƒˆë¡œìš´ ìˆœì„œëŒ€ë¡œ í´ë˜ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ ìƒì„±
        sorted_classes = sorted(list(self.selected_classes), key=int)
        class_names = [id_to_name[cls_id] for cls_id in sorted_classes]
        
        yaml_config = {
            'path': str(self.target_path.absolute()),
            'train': 'images/train',
            'val': 'images/val',
            'names': class_names
        }
        
        yaml_path = self.target_path / 'deepscores_stage3.yaml'
        with open(yaml_path, 'w') as f:
            yaml.dump(yaml_config, f, default_flow_style=False, sort_keys=False)
        
        self.log(f"YAML config saved: {yaml_path}")
        
        # ì œì™¸ëœ í´ë˜ìŠ¤ ì •ë³´ ì €ì¥ (Stage 3ì—ì„œ ê°œì„ ë¨)
        excluded_info = {
            'excluded_classes': list(self.excluded_classes),
            'excluded_class_names': [id_to_name.get(cls_id, f"Unknown_{cls_id}") for cls_id in self.excluded_classes],
            'excluded_details': {
                '42': 'stem - ì–‡ê³  ê²€ì¶œ ì–´ë ¤ì›€',
                '2': 'ledgerLine - ì–‡ê³  ê²€ì¶œ ì–´ë ¤ì›€', 
                '122': 'beam - ë³µì¡í•œ ì—°ê²°ì„ ',
                '123': 'tie - ê³¡ì„ ì´ê³  ì–‡ìŒ',
                '121': 'slur - ê³¡ì„ ì´ê³  ì–‡ìŒ',
                '41': 'augmentationDot - ë§¤ìš° ì‘ì€ ì  (1-2í”½ì…€)',
                '73': 'articStaccatoAbove - ë§¤ìš° ì‘ì€ ì ',
                '74': 'articStaccatoBelow - ë§¤ìš° ì‘ì€ ì ',
                '3': 'repeatDot - ì‘ì€ ì , recall ë‚®ìŒ'
            },
            'remaining_classes': len(self.selected_classes),
            'total_classes': len(stage1_info['classes']),
            'critical_classes_included': {
                'clefG': '6' in self.selected_classes,
                'clefF': any('clef' in id_to_name.get(cls_id, '').lower() for cls_id in self.selected_classes),
                'noteheads': any('notehead' in id_to_name.get(cls_id, '').lower() for cls_id in self.selected_classes),
                'staff': any('staff' in id_to_name.get(cls_id, '').lower() for cls_id in self.selected_classes)
            }
        }
        
        with open(self.target_path / 'excluded_classes_info.json', 'w') as f:
            json.dump(excluded_info, f, indent=2)
    
    def run(self):
        """ì „ì²´ ì „ì²˜ë¦¬ ì‹¤í–‰"""
        self.log("ğŸš€ Stage 3 Data Preprocessing Start")
        self.log(f"ğŸ¯ ì£¼ìš” ê°œì„ ì‚¬í•­: clefG í¬í•¨, beam/tie/slur ì •í™•íˆ ì œì™¸")
        self.log(f"Source: {self.source_path}")
        self.log(f"Target: {self.target_path}")
        self.log(f"Selected classes: {len(self.selected_classes)}")
        self.log(f"Excluded classes: {list(self.excluded_classes)}")
        self.log(f"Image size: {self.image_size}x{self.image_size}")
        self.log(f"Sampling ratio: {self.sample_ratio*100:.1f}%")
        
        # ëœë¤ ì‹œë“œ ì„¤ì •
        random.seed(42)
        
        # JSON íŒŒì¼ ëª©ë¡
        json_files = list(self.source_path.glob("deepscores-complete-*.json"))
        if not json_files:
            self.log("âŒ No JSON files found!")
            return
        
        self.log(f"Found JSON files: {len(json_files)}")
        
        # ê° ë¶„í• ë³„ ìµœëŒ€ ì´ë¯¸ì§€ ìˆ˜ ê³„ì‚°
        total_splits = len(json_files)
        max_images_per_split = self.max_images // total_splits
        
        processed_total = 0
        
        # ê° JSON íŒŒì¼ ì²˜ë¦¬ (train/val ë¶„í• )
        for i, json_file in enumerate(json_files):
            split_name = 'train' if i < len(json_files) * 0.8 else 'val'
            processed = self.process_split(json_file, split_name, max_images_per_split)
            processed_total += processed
        
        self.log(f"\nğŸ‰ Preprocessing complete!")
        self.log(f"Total processed images: {processed_total:,d}")
        self.log(f"Output location: {self.target_path}")
        
        # YAML ì„¤ì • íŒŒì¼ ìƒì„±
        self.create_yaml_config()
        
        # í†µê³„ ì €ì¥
        stats = {
            'total_processed': processed_total,
            'selected_classes': len(self.selected_classes),
            'excluded_classes': list(self.excluded_classes),
            'image_size': self.image_size,
            'sample_ratio': self.sample_ratio,
            'max_images': self.max_images,
            'preprocessing_date': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'stage': 'stage3',
            'improvements_from_stage2': [
                'clefG (ID: 6) ì •ìƒ í¬í•¨',
                'beam (ID: 122) ì •í™•íˆ ì œì™¸',
                'tie (ID: 123) ì •í™•íˆ ì œì™¸', 
                'slur (ID: 121) ì •í™•íˆ ì œì™¸',
                'í´ë˜ìŠ¤ ì´ë¦„ ê²€ì¦ ë‹¨ê³„ ì¶”ê°€'
            ]
        }
        
        with open(self.target_path / 'preprocessing_stats.json', 'w') as f:
            json.dump(stats, f, indent=2)
        
        # ë¡œê·¸ ì €ì¥
        self.save_logs()
        self.log(f"Logs saved to: {self.log_file}")

if __name__ == "__main__":
    # Stage 3 ì „ì²˜ë¦¬ ì‹¤í–‰
    preprocessor = Stage3Preprocessor()
    preprocessor.run()