#!/usr/bin/env python3
"""
DeepScores COCO JSON ë°ì´í„°ì…‹ ì „ì²˜ë¦¬ ë° í’ˆì§ˆ ê²€ì¦ ìŠ¤í¬ë¦½íŠ¸
COCO JSON ì–´ë…¸í…Œì´ì…˜ì„ YOLO í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ê³  ë°ì´í„° í’ˆì§ˆì„ ê²€ì¦í•©ë‹ˆë‹¤.
"""

import os
import sys
import json
import random
import argparse
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from collections import defaultdict, Counter

import numpy as np
import cv2
from tqdm import tqdm
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import matplotlib.patches as patches

class DeepScoresCOCOPreprocessor:
    """DeepScores COCO JSON ë°ì´í„°ì…‹ ì „ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, raw_data_dir: str, output_dir: str, pilot_mode: bool = False, sample_size: int = 1000):
        self.raw_data_dir = Path(raw_data_dir)
        self.output_dir = Path(output_dir)
        self.pilot_mode = pilot_mode
        self.sample_size = sample_size
        
        # ëª©í‘œ í´ë˜ìŠ¤ ì •ì˜ (DeepScores ì‹¤ì œ í´ë˜ìŠ¤ ì´ë¦„ ì‚¬ìš©)
        self.target_classes_phases = {
            'phase_1': ['noteheadBlackOnLine', 'stem', 'clefG'],  # ì±„ì›Œì§„ ìŒí‘œë¨¸ë¦¬, ê¸°ë‘¥, ë†’ì€ìŒìë¦¬í‘œ
            'phase_2': ['restQuarter', 'beam', 'augmentationDot'],  # 4ë¶„ì‰¼í‘œ, ë¹”, ì 
            'phase_3': ['accidentalSharp', 'accidentalFlat', 'accidentalNatural'],  # ì„ì‹œí‘œë“¤
            'phase_4': ['timeSig4', 'noteheadHalfOnLine', 'noteheadWholeOnLine']  # ë°•ìí‘œ, 2ë¶„ìŒí‘œ, ì˜¨ìŒí‘œ
        }
        
        # ì „ì²´ ëª©í‘œ í´ë˜ìŠ¤ (ì´ˆê¸°ì—ëŠ” Phase 1-2ë§Œ ì‚¬ìš©)
        self.target_classes = {}
        class_id = 0
        for phase_classes in self.target_classes_phases.values():
            for class_name in phase_classes:
                self.target_classes[class_name] = class_id
                class_id += 1
        
        self.image_size = 2048  # DeepScores ê³ í•´ìƒë„ ì²˜ë¦¬ (stem ê°€ì‹œì„± í–¥ìƒ)
        self.train_ratio = 0.85
        
        # ê²€ì¦ ê²°ê³¼ ì €ì¥
        self.validation_results = {}
        
        # COCO ë°ì´í„° ì €ì¥
        self.coco_data = {}
        self.category_id_to_name = {}
    
    def load_coco_data(self):
        """COCO JSON íŒŒì¼ë“¤ì„ ë¡œë“œ"""
        train_json = self.raw_data_dir / "deepscores_train.json"
        test_json = self.raw_data_dir / "deepscores_test.json"
        
        print(f"ğŸ“‚ COCO ë°ì´í„° ë¡œë”© ì¤‘...")
        
        # Train ë°ì´í„° ë¡œë“œ
        if train_json.exists():
            with open(train_json, 'r') as f:
                self.coco_data['train'] = json.load(f)
            print(f"   Train: {len(self.coco_data['train']['images'])}ê°œ ì´ë¯¸ì§€, {len(self.coco_data['train']['annotations'])}ê°œ ì–´ë…¸í…Œì´ì…˜")
        else:
            print(f"âš ï¸ Train JSON ì—†ìŒ: {train_json}")
            self.coco_data['train'] = {'images': [], 'annotations': [], 'categories': []}
        
        # Test ë°ì´í„° ë¡œë“œ (validationìœ¼ë¡œ ì‚¬ìš©)
        if test_json.exists():
            with open(test_json, 'r') as f:
                self.coco_data['test'] = json.load(f)
            print(f"   Test: {len(self.coco_data['test']['images'])}ê°œ ì´ë¯¸ì§€, {len(self.coco_data['test']['annotations'])}ê°œ ì–´ë…¸í…Œì´ì…˜")
        else:
            print(f"âš ï¸ Test JSON ì—†ìŒ: {test_json}")
            self.coco_data['test'] = {'images': [], 'annotations': [], 'categories': []}
        
        # ì¹´í…Œê³ ë¦¬ ë§¤í•‘ ìƒì„± (trainì—ì„œ ê°€ì ¸ì˜¤ê¸°, ì—†ìœ¼ë©´ testì—ì„œ)
        categories = self.coco_data.get('train', {}).get('categories', {})
        if not categories:
            categories = self.coco_data.get('test', {}).get('categories', {})
        
        # DeepScores ì¹´í…Œê³ ë¦¬ëŠ” ë”•ì…”ë„ˆë¦¬ í˜•íƒœ: {"1": {"name": "brace", ...}, ...}
        for category_id_str, category_info in categories.items():
            category_id = int(category_id_str)
            self.category_id_to_name[category_id] = category_info['name']
        
        print(f"ğŸ“‹ ì´ ì¹´í…Œê³ ë¦¬ ìˆ˜: {len(self.category_id_to_name)}")
        print(f"ğŸ¯ ëª©í‘œ í´ë˜ìŠ¤: {list(self.target_classes.keys())}")
        
        # ëª©í‘œ í´ë˜ìŠ¤ê°€ ì‹¤ì œë¡œ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        available_classes = set(self.category_id_to_name.values())
        missing_classes = set(self.target_classes.keys()) - available_classes
        if missing_classes:
            print(f"âš ï¸ ë°ì´í„°ì…‹ì— ì—†ëŠ” ëª©í‘œ í´ë˜ìŠ¤: {missing_classes}")
    
    def convert_to_yolo(self, bbox: List[float], img_width: int, img_height: int) -> Tuple[float, float, float, float]:
        """COCO bbox [x, y, width, height] -> YOLO í¬ë§· ë³€í™˜"""
        x, y, width, height = bbox
        
        # YOLO í¬ë§·: [x_center, y_center, width, height] (ëª¨ë‘ 0-1 ì •ê·œí™”)
        x_center = (x + width / 2.0) / img_width
        y_center = (y + height / 2.0) / img_height
        norm_width = width / img_width
        norm_height = height / img_height
        
        return (x_center, y_center, norm_width, norm_height)
    
    def validate_bbox(self, bbox: Tuple[float, float, float, float]) -> bool:
        """YOLO ë°”ìš´ë”© ë°•ìŠ¤ ìœ íš¨ì„± ê²€ì‚¬"""
        x_center, y_center, width, height = bbox
        
        # 0-1 ë²”ìœ„ í™•ì¸
        if not (0 <= x_center <= 1 and 0 <= y_center <= 1):
            return False
        if not (0 < width <= 1 and 0 < height <= 1):
            return False
            
        # ê²½ê³„ í™•ì¸
        if (x_center - width/2 < 0) or (x_center + width/2 > 1):
            return False
        if (y_center - height/2 < 0) or (y_center + height/2 > 1):
            return False
            
        return True
    
    def smart_dataset_sampling(self, subset_data: Dict) -> List[Dict]:
        """í´ë˜ìŠ¤ ê· í˜•ì„ ê³ ë ¤í•œ ì§€ëŠ¥ì  ë°ì´í„° ìƒ˜í”Œë§"""
        images = subset_data['images']
        annotations = subset_data['annotations']
        
        if not self.pilot_mode:
            return images
        
        print(f"ğŸ¯ Pilot Mode: {self.sample_size}ê°œ ìƒ˜í”Œ ì„ íƒ ì¤‘...")
        
        # ì´ë¯¸ì§€ë³„ ì–´ë…¸í…Œì´ì…˜ ê·¸ë£¹í•‘ (DeepScoresëŠ” annotationsê°€ ë”•ì…”ë„ˆë¦¬)
        img_id_to_anns = defaultdict(list)
        for ann_id, ann in annotations.items():
            try:
                img_id = int(ann['img_id'])  # ë¬¸ìì—´ì„ ì •ìˆ˜ë¡œ ë³€í™˜
                img_id_to_anns[img_id].append(ann)
            except (ValueError, TypeError, KeyError):
                continue  # ì˜ëª»ëœ img_idëŠ” ë¬´ì‹œ
        
        # ê° ì´ë¯¸ì§€ì˜ íƒ€ê²Ÿ í´ë˜ìŠ¤ ë¶„í¬ ë¶„ì„
        image_class_counts = {}
        target_class_names = set(self.target_classes.keys())
        
        for img in tqdm(images[:5000], desc="í´ë˜ìŠ¤ ë¶„í¬ ë¶„ì„"):  # ìµœëŒ€ 5000ê°œë§Œ ë¶„ì„
            img_id = img['id']
            class_counts = Counter()
            
            for ann in img_id_to_anns.get(img_id, []):
                cat_ids = ann['cat_id']  # DeepScoresëŠ” cat_idê°€ ë¦¬ìŠ¤íŠ¸
                if isinstance(cat_ids, str):
                    cat_ids = [cat_ids]  # ë‹¨ì¼ ë¬¸ìì—´ì¸ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                
                for cat_id_str in cat_ids:
                    if cat_id_str is None or cat_id_str == '':
                        continue
                    
                    try:
                        category_id = int(cat_id_str)
                        class_name = self.category_id_to_name.get(category_id, '')
                        
                        if class_name in target_class_names:
                            class_counts[class_name] += 1
                    except (ValueError, TypeError):
                        continue
            
            if class_counts:  # íƒ€ê²Ÿ í´ë˜ìŠ¤ê°€ í•˜ë‚˜ë¼ë„ ìˆëŠ” ì´ë¯¸ì§€ë§Œ
                filename = img.get('filename', img.get('file_name', f"unknown_{img.get('id', 'img')}"))
                image_class_counts[filename] = (img, class_counts)
        
        # ê· í˜•ì¡íŒ ìƒ˜í”Œë§
        sampled_images = []
        class_samples = defaultdict(list)
        
        # í´ë˜ìŠ¤ë³„ë¡œ ì´ë¯¸ì§€ ê·¸ë£¹í•‘
        for file_name, (img_info, class_counts) in image_class_counts.items():
            for class_name, count in class_counts.items():
                class_samples[class_name].append((img_info, count))
        
        # ê° í´ë˜ìŠ¤ì—ì„œ ê· ë“±í•˜ê²Œ ìƒ˜í”Œë§
        samples_per_class = max(50, self.sample_size // len(self.target_classes))  # í´ë˜ìŠ¤ë‹¹ ìµœì†Œ 50ê°œ
        
        for class_name, images_with_counts in class_samples.items():
            # í•´ë‹¹ í´ë˜ìŠ¤ê°€ ë§ì´ í¬í•¨ëœ ì´ë¯¸ì§€ ìš°ì„  ì„ íƒ
            images_with_counts.sort(key=lambda x: x[1], reverse=True)
            selected = [img_info for img_info, _ in images_with_counts[:samples_per_class]]
            sampled_images.extend(selected)
        
        # ì¤‘ë³µ ì œê±° ë° ìµœì¢… ìƒ˜í”Œ ìˆ˜ ì¡°ì •
        unique_images = {}
        for img in sampled_images:
            filename = img.get('filename', img.get('file_name', f"unknown_{img.get('id', 'img')}"))
            unique_images[filename] = img
        sampled_images = list(unique_images.values())
        
        if len(sampled_images) > self.sample_size:
            sampled_images = random.sample(sampled_images, self.sample_size)
        
        print(f"âœ… {len(sampled_images)}ê°œ ìƒ˜í”Œ ì„ íƒ ì™„ë£Œ")
        return sampled_images
    
    def process_dataset(self):
        """ë©”ì¸ ë°ì´í„°ì…‹ ì²˜ë¦¬ í•¨ìˆ˜"""
        print("ğŸš€ DeepScores COCO ë°ì´í„°ì…‹ ì „ì²˜ë¦¬ ì‹œì‘")
        print(f"ì›ë³¸ ë°ì´í„°: {self.raw_data_dir}")
        print(f"ì¶œë ¥ ë””ë ‰í„°ë¦¬: {self.output_dir}")
        print(f"Pilot Mode: {self.pilot_mode} (ìƒ˜í”Œ í¬ê¸°: {self.sample_size})")
        print("=" * 60)
        
        # COCO ë°ì´í„° ë¡œë“œ
        self.load_coco_data()
        
        # ì¶œë ¥ ë””ë ‰í„°ë¦¬ ìƒì„±
        for subset in ['train', 'val']:
            (self.output_dir / 'images' / subset).mkdir(parents=True, exist_ok=True)
            (self.output_dir / 'labels' / subset).mkdir(parents=True, exist_ok=True)
        
        # ì´ë¯¸ì§€ ë””ë ‰í„°ë¦¬ í™•ì¸
        images_dir = self.raw_data_dir / "images"
        if not images_dir.exists():
            raise FileNotFoundError(f"ì´ë¯¸ì§€ ë””ë ‰í„°ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {images_dir}")
        
        # ë°ì´í„°ì…‹ ë¶„í•  ë° ì²˜ë¦¬
        processing_stats = {
            'total_images': 0,
            'processed_images': 0,
            'total_annotations': 0,
            'valid_annotations': 0,
            'invalid_bboxes': 0,
            'missing_files': 0,
            'class_distribution': Counter()
        }
        
        # Train ë°ì´í„° ì²˜ë¦¬
        if self.coco_data['train']['images']:
            print(f"\nğŸ”„ TRAIN ë°ì´í„°ì…‹ ì²˜ë¦¬ ì¤‘...")
            train_images = self.smart_dataset_sampling(self.coco_data['train'])
            self._process_subset(
                'train', train_images, self.coco_data['train']['annotations'], 
                images_dir, processing_stats
            )
        
        # Test ë°ì´í„°ë¥¼ Validationìœ¼ë¡œ ì‚¬ìš©
        if self.coco_data['test']['images']:
            print(f"\nğŸ”„ VALIDATION ë°ì´í„°ì…‹ ì²˜ë¦¬ ì¤‘...")
            # Test ë°ì´í„°ëŠ” ìƒ˜í”Œë§ ì—†ì´ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê±°ë‚˜ ì ì€ ì–‘ë§Œ ì‚¬ìš©
            test_images = self.coco_data['test']['images']
            if self.pilot_mode:
                test_images = random.sample(test_images, min(200, len(test_images)))
            
            self._process_subset(
                'val', test_images, self.coco_data['test']['annotations'], 
                images_dir, processing_stats
            )
        
        # ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½
        self._print_processing_summary(processing_stats)
        
        # YAML ì„¤ì • íŒŒì¼ ìƒì„±
        self._create_dataset_yaml()
        
        # ë°ì´í„° í’ˆì§ˆ ê²€ì¦ ì‹¤í–‰
        self._validate_dataset_quality(processing_stats)
        
        print("\nğŸ‰ ë°ì´í„°ì…‹ ì „ì²˜ë¦¬ ì™„ë£Œ!")
    
    def _process_subset(self, subset_name: str, images: List[Dict], annotations: List[Dict], 
                       images_dir: Path, processing_stats: Dict):
        """ê°œë³„ subset (train/val) ì²˜ë¦¬"""
        
        # ì´ë¯¸ì§€ë³„ ì–´ë…¸í…Œì´ì…˜ ê·¸ë£¹í•‘ (DeepScoresëŠ” annotationsê°€ ë”•ì…”ë„ˆë¦¬)
        img_id_to_anns = defaultdict(list)
        for ann_id, ann in annotations.items():
            try:
                img_id = int(ann['img_id'])
                img_id_to_anns[img_id].append(ann)
            except (ValueError, TypeError, KeyError):
                continue  # ì˜ëª»ëœ img_idëŠ” ë¬´ì‹œ
        
        # íƒ€ê²Ÿ í´ë˜ìŠ¤ ID ë§¤í•‘
        target_category_ids = {}
        for cat_id, cat_name in self.category_id_to_name.items():
            if cat_name in self.target_classes:
                target_category_ids[cat_id] = self.target_classes[cat_name]
        
        img_out_path = self.output_dir / 'images' / subset_name
        lbl_out_path = self.output_dir / 'labels' / subset_name
        
        for img_info in tqdm(images, desc=f"Processing {subset_name}"):
            processing_stats['total_images'] += 1
            
            try:
                # ì›ë³¸ ì´ë¯¸ì§€ ì²˜ë¦¬
                img_file = img_info.get('filename', img_info.get('file_name', f"unknown_{img_info.get('id', 'img')}"))
                img_path = images_dir / img_file
                
                if not img_path.exists():
                    processing_stats['missing_files'] += 1
                    continue
                
                original_img = cv2.imread(str(img_path))
                if original_img is None:
                    processing_stats['missing_files'] += 1
                    continue
                
                orig_height, orig_width = original_img.shape[:2]
                
                # ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ ë° ì €ì¥ (aspect ratio ìœ ì§€)
                scale_x = self.image_size / orig_width
                scale_y = self.image_size / orig_height
                scale = min(scale_x, scale_y)  # ë” ì‘ì€ ìŠ¤ì¼€ì¼ ì‚¬ìš©í•˜ì—¬ aspect ratio ìœ ì§€
                
                new_width = int(orig_width * scale)
                new_height = int(orig_height * scale)
                
                resized_img = cv2.resize(original_img, (new_width, new_height))
                
                # ì •ì‚¬ê°í˜• íŒ¨ë”© ì¶”ê°€ (í•„ìš”í•œ ê²½ìš°)
                if new_width != self.image_size or new_height != self.image_size:
                    padded_img = np.zeros((self.image_size, self.image_size, 3), dtype=np.uint8)
                    y_offset = (self.image_size - new_height) // 2
                    x_offset = (self.image_size - new_width) // 2
                    padded_img[y_offset:y_offset+new_height, x_offset:x_offset+new_width] = resized_img
                    final_img = padded_img
                    
                    # ìŠ¤ì¼€ì¼ê³¼ ì˜¤í”„ì…‹ ê³„ì‚° (ë™ì¼í•œ ìŠ¤ì¼€ì¼ ì‚¬ìš©)
                    scale_x = scale
                    scale_y = scale
                else:
                    final_img = resized_img
                    scale_x = scale
                    scale_y = scale
                    x_offset = y_offset = 0
                
                cv2.imwrite(str(img_out_path / img_file), final_img)
                
                # í•´ë‹¹ ì´ë¯¸ì§€ì˜ ì–´ë…¸í…Œì´ì…˜ ì²˜ë¦¬
                img_id = img_info['id']
                image_annotations = img_id_to_anns.get(img_id, [])
                
                yolo_labels = []
                for ann in image_annotations:
                    processing_stats['total_annotations'] += 1
                    
                    # DeepScoresëŠ” cat_idê°€ ë¦¬ìŠ¤íŠ¸ì´ê³ , bboxëŠ” a_bbox ì‚¬ìš©
                    cat_ids = ann['cat_id']
                    if isinstance(cat_ids, str):
                        cat_ids = [cat_ids]
                    
                    # ì²« ë²ˆì§¸ target categoryë§Œ ì‚¬ìš© (ë©€í‹° ë¼ë²¨ ì²˜ë¦¬ëŠ” ë³µì¡í•˜ë¯€ë¡œ ë‹¨ìˆœí™”)
                    target_found = False
                    for cat_id_str in cat_ids:
                        if cat_id_str is None or cat_id_str == '':
                            continue
                            
                        try:
                            category_id = int(cat_id_str)
                            if category_id in target_category_ids:
                                yolo_class_id = target_category_ids[category_id]
                                target_found = True
                                break
                        except (ValueError, TypeError):
                            continue
                    
                    if not target_found:
                        continue
                    
                    # DeepScoresëŠ” a_bbox ì‚¬ìš©: [x_min, y_min, x_max, y_max]
                    a_bbox = ann['a_bbox']
                    if len(a_bbox) != 4:
                        continue
                    
                    # [x_min, y_min, x_max, y_max] -> [x, y, width, height] ë³€í™˜
                    x_min, y_min, x_max, y_max = a_bbox
                    bbox = [x_min, y_min, x_max - x_min, y_max - y_min]
                    
                    # ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ìƒˆ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ê²Œ ì¡°ì •
                    x, y, width, height = bbox
                    
                    # ì›ë³¸ ì¢Œí‘œë¥¼ ìƒˆ ì¢Œí‘œë¡œ ë³€í™˜
                    new_x = x * scale_x + x_offset
                    new_y = y * scale_y + y_offset
                    new_width = width * scale_x
                    new_height = height * scale_y
                    
                    # YOLO í¬ë§·ìœ¼ë¡œ ë³€í™˜ (ìµœì¢… ì´ë¯¸ì§€ í¬ê¸° ê¸°ì¤€)
                    yolo_bbox = self.convert_to_yolo(
                        [new_x, new_y, new_width, new_height], 
                        self.image_size, self.image_size
                    )
                    
                    # ë°”ìš´ë”© ë°•ìŠ¤ ìœ íš¨ì„± ê²€ì‚¬
                    if not self.validate_bbox(yolo_bbox):
                        processing_stats['invalid_bboxes'] += 1
                        continue
                    
                    yolo_labels.append(f"{yolo_class_id} {' '.join(map(str, yolo_bbox))}")
                    processing_stats['valid_annotations'] += 1
                    
                    class_name = self.category_id_to_name[category_id]
                    processing_stats['class_distribution'][class_name] += 1
                
                # ë¼ë²¨ íŒŒì¼ ì €ì¥
                label_file = lbl_out_path / (Path(img_file).stem + '.txt')
                with open(label_file, 'w') as f:
                    f.write('\n'.join(yolo_labels))
                
                processing_stats['processed_images'] += 1
                
            except Exception as e:
                print(f"ì˜¤ë¥˜: {img_file} ì²˜ë¦¬ ì‹¤íŒ¨ - {str(e)}")
                continue
    
    def _print_processing_summary(self, stats: Dict):
        """ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print("\n" + "=" * 60)
        print("ğŸ“ˆ ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½")
        print("=" * 60)
        print(f"ì´ ì´ë¯¸ì§€ ìˆ˜: {stats['total_images']}")
        print(f"ì„±ê³µì ìœ¼ë¡œ ì²˜ë¦¬ëœ ì´ë¯¸ì§€: {stats['processed_images']}")
        print(f"ì´ ì–´ë…¸í…Œì´ì…˜ ìˆ˜: {stats['total_annotations']}")
        print(f"ìœ íš¨í•œ ì–´ë…¸í…Œì´ì…˜ ìˆ˜: {stats['valid_annotations']}")
        print(f"ë¬´íš¨í•œ ë°”ìš´ë”© ë°•ìŠ¤: {stats['invalid_bboxes']}")
        print(f"ëˆ„ë½ëœ íŒŒì¼: {stats['missing_files']}")
        
        print(f"\nğŸ“Š í´ë˜ìŠ¤ ë¶„í¬:")
        for class_name, count in stats['class_distribution'].most_common():
            percentage = (count / stats['valid_annotations']) * 100 if stats['valid_annotations'] > 0 else 0
            print(f"  {class_name}: {count} ({percentage:.1f}%)")
    
    def _create_dataset_yaml(self):
        """YAML ì„¤ì • íŒŒì¼ ìƒì„±"""
        yaml_content = f"""# DeepScores Dataset Configuration for YOLOv8
path: {self.output_dir.absolute()}
train: images/train
val: images/val

# Classes ({len(self.target_classes)} classes)
names:
"""
        
        for class_name, class_id in sorted(self.target_classes.items(), key=lambda x: x[1]):
            yaml_content += f"  {class_id}: {class_name}\n"
        
        yaml_file = self.output_dir / "deepscores.yaml"
        with open(yaml_file, 'w') as f:
            f.write(yaml_content)
        
        print(f"ğŸ“„ YAML ì„¤ì • íŒŒì¼ ìƒì„±: {yaml_file}")
    
    def _validate_dataset_quality(self, processing_stats: Dict):
        """ë°ì´í„°ì…‹ í’ˆì§ˆ ê²€ì¦"""
        print("\nğŸ” ë°ì´í„°ì…‹ í’ˆì§ˆ ê²€ì¦ ì¤‘...")
        
        validation_results = {
            'processing_stats': processing_stats,
            'image_label_pairs': self._check_image_label_pairs(),
            'class_imbalance': self._analyze_class_imbalance(processing_stats['class_distribution']),
            'sample_visualization': self._create_sample_visualization()
        }
        
        # ê²€ì¦ ë¦¬í¬íŠ¸ ì €ì¥
        report_dir = Path("validation_reports")
        report_dir.mkdir(exist_ok=True)
        
        from datetime import datetime
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        report_file = report_dir / f"coco_preprocessing_validation_{timestamp}.json"
        
        with open(report_file, 'w') as f:
            # Counter ê°ì²´ë¥¼ dictë¡œ ë³€í™˜í•˜ì—¬ JSON ì§ë ¬í™” ê°€ëŠ¥í•˜ê²Œ í•¨
            serializable_results = validation_results.copy()
            serializable_results['processing_stats']['class_distribution'] = dict(processing_stats['class_distribution'])
            json.dump(serializable_results, f, indent=2)
        
        print(f"ğŸ“‹ ê²€ì¦ ë¦¬í¬íŠ¸ ì €ì¥: {report_file}")
        
        self.validation_results = validation_results
    
    def _check_image_label_pairs(self) -> Dict:
        """ì´ë¯¸ì§€-ë¼ë²¨ ìŒ ë§¤ì¹­ í™•ì¸"""
        results = {'train': {}, 'val': {}}
        
        for subset in ['train', 'val']:
            img_dir = self.output_dir / 'images' / subset
            lbl_dir = self.output_dir / 'labels' / subset
            
            img_files = set(f.stem for f in img_dir.glob('*.png'))
            lbl_files = set(f.stem for f in lbl_dir.glob('*.txt'))
            
            results[subset] = {
                'total_images': len(img_files),
                'total_labels': len(lbl_files),
                'missing_labels': len(img_files - lbl_files),
                'orphan_labels': len(lbl_files - img_files),
                'matched_pairs': len(img_files & lbl_files)
            }
        
        return results
    
    def _analyze_class_imbalance(self, class_distribution: Counter) -> Dict:
        """í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¶„ì„"""
        if not class_distribution:
            return {'status': 'no_data'}
        
        total = sum(class_distribution.values())
        class_ratios = {cls: count/total for cls, count in class_distribution.items()}
        
        # ë¶ˆê· í˜• ì‹¬ê°ë„ ê³„ì‚°
        max_ratio = max(class_ratios.values())
        min_ratio = min(class_ratios.values())
        imbalance_ratio = max_ratio / min_ratio if min_ratio > 0 else float('inf')
        
        # ê¶Œì¥ì‚¬í•­ ìƒì„±
        recommendations = []
        if imbalance_ratio > 50:
            recommendations.append("ì‹¬ê°í•œ í´ë˜ìŠ¤ ë¶ˆê· í˜• - weighted loss í•¨ìˆ˜ ì‚¬ìš© ê¶Œì¥")
        if imbalance_ratio > 20:
            recommendations.append("í´ë˜ìŠ¤ë³„ ë°ì´í„° augmentation ì°¨ë“± ì ìš© ê¶Œì¥")
        if min_ratio < 0.01:  # 1% ë¯¸ë§Œ
            recommendations.append("í¬ê·€ í´ë˜ìŠ¤ì— ëŒ€í•œ oversampling ê¶Œì¥")
        
        return {
            'imbalance_ratio': imbalance_ratio,
            'class_ratios': class_ratios,
            'recommendations': recommendations
        }
    
    def _create_sample_visualization(self, num_samples: int = 10) -> Dict:
        """ìƒ˜í”Œ ì´ë¯¸ì§€ ì‹œê°í™”"""
        print("ğŸ“¸ ìƒ˜í”Œ ì‹œê°í™” ìƒì„± ì¤‘...")
        
        try:
            train_img_dir = self.output_dir / 'images' / 'train'
            train_lbl_dir = self.output_dir / 'labels' / 'train'
            
            img_files = list(train_img_dir.glob('*.png'))
            if len(img_files) == 0:
                return {'status': 'no_images'}
            
            sample_files = random.sample(img_files, min(num_samples, len(img_files)))
            
            # ì‹œê°í™” ìƒì„±
            fig, axes = plt.subplots(2, 5, figsize=(20, 8))
            axes = axes.flatten()
            
            visualized_count = 0
            
            for i, img_file in enumerate(sample_files):
                if i >= len(axes):
                    break
                
                # ì´ë¯¸ì§€ ë¡œë“œ
                image = cv2.imread(str(img_file))
                if image is None:
                    continue
                    
                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                
                # ë¼ë²¨ ë¡œë“œ
                label_file = train_lbl_dir / (img_file.stem + '.txt')
                
                ax = axes[i]
                ax.imshow(image_rgb)
                ax.set_title(f"{img_file.stem}")
                ax.axis('off')
                
                if label_file.exists():
                    with open(label_file, 'r') as f:
                        lines = f.read().strip().split('\n')
                        
                    h, w = image_rgb.shape[:2]
                    
                    for line in lines:
                        if not line.strip():
                            continue
                        parts = line.split()
                        if len(parts) != 5:
                            continue
                        
                        class_id, x_center, y_center, width, height = map(float, parts)
                        
                        # YOLO -> í”½ì…€ ì¢Œí‘œ ë³€í™˜
                        x1 = (x_center - width/2) * w
                        y1 = (y_center - height/2) * h
                        box_width = width * w
                        box_height = height * h
                        
                        rect = patches.Rectangle(
                            (x1, y1), box_width, box_height,
                            linewidth=2, edgecolor='red', facecolor='none'
                        )
                        ax.add_patch(rect)
                        
                        # í´ë˜ìŠ¤ ì´ë¦„ í‘œì‹œ
                        class_name = [name for name, id in self.target_classes.items() if id == int(class_id)]
                        class_name = class_name[0] if class_name else f"Class_{int(class_id)}"
                        
                        ax.text(x1, y1-5, class_name, color='red', fontsize=8, 
                               bbox=dict(boxstyle="round,pad=0.2", facecolor='white', alpha=0.7))
                
                visualized_count += 1
            
            # ë¹ˆ subplot ìˆ¨ê¸°ê¸°
            for i in range(visualized_count, len(axes)):
                axes[i].axis('off')
            
            plt.tight_layout()
            
            # ì‹œê°í™” ì €ì¥
            vis_dir = Path("validation_reports")
            vis_dir.mkdir(exist_ok=True)
            
            from datetime import datetime
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            vis_file = vis_dir / f"coco_sample_visualization_{timestamp}.png"
            
            plt.savefig(vis_file, dpi=150, bbox_inches='tight')
            plt.close()
            
            return {
                'status': 'success',
                'visualized_samples': visualized_count,
                'output_file': str(vis_file)
            }
            
        except Exception as e:
            return {
                'status': 'error',
                'error': str(e)
            }


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="DeepScores COCO ë°ì´í„°ì…‹ ì „ì²˜ë¦¬")
    parser.add_argument("--raw-data", default="ds2_dense", help="ì›ë³¸ DeepScores ë°ì´í„° ë””ë ‰í„°ë¦¬")
    parser.add_argument("--output", default="data", help="ì¶œë ¥ ë””ë ‰í„°ë¦¬")
    parser.add_argument("--pilot-mode", action="store_true", help="Pilot ëª¨ë“œ (ìƒ˜í”Œ ë°ì´í„°ë§Œ ì²˜ë¦¬)")
    parser.add_argument("--sample-size", type=int, default=1000, help="Pilot ëª¨ë“œ ìƒ˜í”Œ í¬ê¸°")
    
    args = parser.parse_args()
    
    processor = DeepScoresCOCOPreprocessor(
        raw_data_dir=args.raw_data,
        output_dir=args.output,
        pilot_mode=args.pilot_mode,
        sample_size=args.sample_size
    )
    
    try:
        processor.process_dataset()
        print("âœ… ì „ì²˜ë¦¬ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ ì „ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()