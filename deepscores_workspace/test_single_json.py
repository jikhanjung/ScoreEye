#!/usr/bin/env python3
"""
ë‹¨ì¼ JSON íŒŒì¼ë¡œ ì „ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
"""

import json
import os
import cv2
import numpy as np
from pathlib import Path
import random
from collections import defaultdict
from tqdm import tqdm
import shutil

class SingleJSONProcessor:
    def __init__(self):
        # ì„¤ì • ë¡œë“œ
        with open('stage1_preprocess_config.json', 'r') as f:
            config = json.load(f)
        
        self.source_path = Path(config['source_path'])
        self.target_path = Path('./test_data')
        self.selected_classes = set(str(cls_id) for cls_id in config['selected_classes'])
        self.class_mapping = config['class_mapping']
        self.image_size = config['image_size']
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        self.setup_directories()
    
    def setup_directories(self):
        """í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±"""
        if self.target_path.exists():
            shutil.rmtree(self.target_path)
        
        dirs = ['images', 'labels']
        for dir_name in dirs:
            (self.target_path / dir_name).mkdir(parents=True, exist_ok=True)
    
    def convert_bbox_to_yolo(self, bbox, img_width, img_height):
        """DeepScores bboxë¥¼ YOLO í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        DeepScoresì˜ a_bboxëŠ” [x1, y1, x2, y2] í˜•ì‹
        """
        x1, y1, x2, y2 = bbox
        
        # width, height ê³„ì‚°
        width = abs(x2 - x1)
        height = abs(y2 - y1)
        
        # ì¤‘ì‹¬ì  ì¢Œí‘œ ê³„ì‚°
        center_x = (x1 + x2) / 2
        center_y = (y1 + y2) / 2
        
        # ì •ê·œí™”
        center_x /= img_width
        center_y /= img_height
        width /= img_width
        height /= img_height
        
        # ì¢Œí‘œê°€ 0-1 ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ì§€ ì•Šë„ë¡ í´ë¦¬í•‘
        center_x = max(0.0, min(1.0, center_x))
        center_y = max(0.0, min(1.0, center_y))
        width = max(0.0, min(1.0, width))
        height = max(0.0, min(1.0, height))
        
        return [center_x, center_y, width, height]
    
    def process_single_json(self, json_file, max_images=10):
        """ë‹¨ì¼ JSON íŒŒì¼ ì²˜ë¦¬"""
        print(f"ğŸ“– ì²˜ë¦¬ ì¤‘: {json_file}")
        
        with open(json_file, 'r') as f:
            data = json.load(f)
        
        categories = data['categories']
        images = data['images']
        annotations = data['annotations']
        
        # í•„í„°ë§ëœ ì–´ë…¸í…Œì´ì…˜ ìˆ˜ì§‘
        filtered_annotations = defaultdict(list)
        annotation_count = 0
        
        if isinstance(annotations, dict):
            for ann_id, ann in annotations.items():
                cat_id = ann.get('cat_id')
                if cat_id:
                    if isinstance(cat_id, list):
                        cat_id = cat_id[0] if cat_id else None
                    
                    if cat_id and cat_id in self.selected_classes:
                        image_id = ann.get('img_id') or ann.get('image_id')
                        bbox = ann.get('a_bbox') or ann.get('bbox', [0, 0, 1, 1])
                        
                        if image_id and bbox:
                            filtered_annotations[image_id].append({
                                'cat_id': cat_id,
                                'bbox': bbox,
                                'area': ann.get('area', 1)
                            })
                            annotation_count += 1
        
        print(f"âœ… í•„í„°ë§ ì™„ë£Œ: {annotation_count:,d}ê°œ ì–´ë…¸í…Œì´ì…˜, {len(filtered_annotations):,d}ê°œ ì´ë¯¸ì§€")
        
        # ì²˜ìŒ Nê°œ ì´ë¯¸ì§€ë§Œ ì²˜ë¦¬
        image_list = list(filtered_annotations.keys())[:max_images]
        
        processed_count = 0
        error_count = 0
        bbox_errors = []
        
        for image_id in tqdm(image_list, desc="Processing images"):
            print(f"\nğŸ” ì´ë¯¸ì§€ ID ê²€ìƒ‰: {image_id} (íƒ€ì…: {type(image_id)})")
            
            # ì´ë¯¸ì§€ ì •ë³´ ì°¾ê¸°
            image_info = None
            if isinstance(images, dict):
                print(f"   imagesëŠ” dict íƒ€ì…, í‚¤ ìƒ˜í”Œ: {list(images.keys())[:3]}")
                image_info = images.get(str(image_id)) or images.get(image_id)
                if not image_info:
                    # ëª¨ë“  í‚¤ë¥¼ í™•ì¸í•´ë³´ê¸°
                    for key, value in list(images.items())[:3]:
                        print(f"   ìƒ˜í”Œ í‚¤: {key} (íƒ€ì…: {type(key)}) -> {value.get('filename', 'no filename')}")
            else:
                print(f"   imagesëŠ” list íƒ€ì…, ê¸¸ì´: {len(images)}")
                for img in images[:3]:
                    img_id = img.get('id')
                    print(f"   ìƒ˜í”Œ ID: {img_id} (íƒ€ì…: {type(img_id)}) -> {img.get('filename', 'no filename')}")
                    if img_id == image_id or str(img_id) == str(image_id):
                        image_info = img
                        break
            
            if image_info:
                print(f"   âœ… ì´ë¯¸ì§€ ì •ë³´ ë°œê²¬: {image_info.get('filename', 'no filename')}")
            else:
                print(f"   âŒ ì´ë¯¸ì§€ ì •ë³´ ì—†ìŒ")
                error_count += 1
                continue
            
            # íŒŒì¼ ê²½ë¡œ
            filename = image_info.get('filename') or image_info.get('file_name', f"{image_id}.png")
            image_path = self.source_path / 'images' / filename
            
            if not image_path.exists():
                print(f"âŒ ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ: {image_path}")
                error_count += 1
                continue
            
            # ì´ë¯¸ì§€ ë¡œë“œ
            image = cv2.imread(str(image_path))
            if image is None:
                print(f"âŒ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {image_path}")
                error_count += 1
                continue
            
            orig_height, orig_width = image.shape[:2]
            print(f"\nğŸ–¼ï¸  ì´ë¯¸ì§€: {filename}")
            print(f"   ì›ë³¸ í¬ê¸°: {orig_width}x{orig_height}")
            
            # ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ
            scale = self.image_size / max(orig_width, orig_height)
            new_width = int(orig_width * scale)
            new_height = int(orig_height * scale)
            
            resized = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)
            
            # íŒ¨ë”© ì¶”ê°€
            pad_x = (self.image_size - new_width) // 2
            pad_y = (self.image_size - new_height) // 2
            
            processed_image = np.full((self.image_size, self.image_size, 3), 255, dtype=np.uint8)
            processed_image[pad_y:pad_y+new_height, pad_x:pad_x+new_width] = resized
            
            print(f"   ìŠ¤ì¼€ì¼: {scale:.3f}, ìƒˆ í¬ê¸°: {new_width}x{new_height}")
            print(f"   íŒ¨ë”©: ({pad_x}, {pad_y})")
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ì²˜ë¦¬
            yolo_labels = []
            valid_boxes = 0
            invalid_boxes = 0
            
            for ann in filtered_annotations[image_id]:
                cat_id = ann['cat_id']
                bbox = ann['bbox']
                x1, y1, x2, y2 = bbox
                
                print(f"   ğŸ“¦ ì›ë³¸ bbox: [{x1:.1f}, {y1:.1f}, {x2:.1f}, {y2:.1f}]")
                
                # ì›ë³¸ ì´ë¯¸ì§€ ë²”ìœ„ ê²€ì‚¬
                if (x1 < 0 or y1 < 0 or x2 > orig_width or y2 > orig_height or
                    x1 >= x2 or y1 >= y2):
                    print(f"      âŒ ì›ë³¸ ë²”ìœ„ ì´ˆê³¼")
                    invalid_boxes += 1
                    bbox_errors.append({
                        'image': filename,
                        'original_bbox': bbox,
                        'image_size': (orig_width, orig_height),
                        'error': 'original_bounds'
                    })
                    continue
                
                # ìŠ¤ì¼€ì¼ë§ ì ìš©
                x1_scaled = x1 * scale
                y1_scaled = y1 * scale
                x2_scaled = x2 * scale
                y2_scaled = y2 * scale
                
                # íŒ¨ë”© ì ìš©
                x1_final = x1_scaled + pad_x
                y1_final = y1_scaled + pad_y
                x2_final = x2_scaled + pad_x
                y2_final = y2_scaled + pad_y
                
                print(f"      ìŠ¤ì¼€ì¼ë§ í›„: [{x1_scaled:.1f}, {y1_scaled:.1f}, {x2_scaled:.1f}, {y2_scaled:.1f}]")
                print(f"      íŒ¨ë”© í›„: [{x1_final:.1f}, {y1_final:.1f}, {x2_final:.1f}, {y2_final:.1f}]")
                
                # ìµœì¢… ë²”ìœ„ ê²€ì‚¬
                if (x1_final < 0 or y1_final < 0 or 
                    x2_final > self.image_size or y2_final > self.image_size):
                    print(f"      âŒ ìµœì¢… ë²”ìœ„ ì´ˆê³¼")
                    invalid_boxes += 1
                    bbox_errors.append({
                        'image': filename,
                        'final_bbox': [x1_final, y1_final, x2_final, y2_final],
                        'image_size': (self.image_size, self.image_size),
                        'error': 'final_bounds'
                    })
                    continue
                
                # í¬ê¸° ê²€ì‚¬
                width_final = x2_final - x1_final
                height_final = y2_final - y1_final
                if width_final < 1 or height_final < 1:
                    print(f"      âŒ ë„ˆë¬´ ì‘ìŒ")
                    invalid_boxes += 1
                    continue
                
                # YOLO ë³€í™˜
                yolo_bbox = self.convert_bbox_to_yolo([x1_final, y1_final, x2_final, y2_final], 
                                                     self.image_size, self.image_size)
                
                print(f"      YOLO: [{yolo_bbox[0]:.4f}, {yolo_bbox[1]:.4f}, {yolo_bbox[2]:.4f}, {yolo_bbox[3]:.4f}]")
                
                # ìµœì¢… ê²€ì¦
                if all(0.0 <= coord <= 1.0 for coord in yolo_bbox):
                    cat_id_str = str(cat_id)
                    if cat_id_str in self.class_mapping:
                        class_id = self.class_mapping[cat_id_str]
                        class_name = categories[cat_id_str]['name']
                        yolo_labels.append(f"{class_id} {' '.join(map(str, yolo_bbox))}")
                        print(f"      âœ… ìœ íš¨: {class_name} (ID: {class_id})")
                        valid_boxes += 1
                else:
                    print(f"      âŒ YOLO ì¢Œí‘œ ë²”ìœ„ ì´ˆê³¼")
                    invalid_boxes += 1
                    bbox_errors.append({
                        'image': filename,
                        'yolo_bbox': yolo_bbox,
                        'error': 'yolo_bounds'
                    })
            
            print(f"   ğŸ“Š ìœ íš¨: {valid_boxes}, ë¬´íš¨: {invalid_boxes}")
            
            # íŒŒì¼ ì €ì¥
            output_image_path = self.target_path / 'images' / filename
            output_label_path = self.target_path / 'labels' / (Path(filename).stem + '.txt')
            
            cv2.imwrite(str(output_image_path), processed_image)
            
            if yolo_labels:
                with open(output_label_path, 'w') as f:
                    f.write('\n'.join(yolo_labels))
            else:
                output_label_path.touch()
            
            processed_count += 1
        
        print(f"\nğŸ“Š ì²˜ë¦¬ ê²°ê³¼:")
        print(f"   ì„±ê³µ: {processed_count}ê°œ")
        print(f"   ì‹¤íŒ¨: {error_count}ê°œ")
        print(f"   ë°”ìš´ë”© ë°•ìŠ¤ ì˜¤ë¥˜: {len(bbox_errors)}ê°œ")
        
        if bbox_errors:
            print(f"\nâŒ ë°”ìš´ë”© ë°•ìŠ¤ ì˜¤ë¥˜ ìƒ˜í”Œ:")
            for i, error in enumerate(bbox_errors[:5]):
                print(f"   {i+1}. {error}")

if __name__ == "__main__":
    processor = SingleJSONProcessor()
    processor.process_single_json("/mnt/f/ds2_complete/deepscores-complete-0_test.json", max_images=5)