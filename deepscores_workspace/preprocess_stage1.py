#!/usr/bin/env python3
"""
Stage 1 DeepScores ë°ì´í„° ì „ì²˜ë¦¬ ìŠ¤í¬ë¦½íŠ¸
50ê°œ í•µì‹¬ í´ë˜ìŠ¤ë¡œ ì œí•œí•œ ë°ì´í„°ì…‹ ìƒì„±
"""

import json
import os
import cv2
import numpy as np
from pathlib import Path
import random
from collections import defaultdict
import yaml
from tqdm import tqdm
import shutil

class Stage1Preprocessor:
    def __init__(self, config_file='stage1_preprocess_config.json'):
        with open(config_file, 'r') as f:
            self.config = json.load(f)
        
        self.source_path = Path(self.config['source_path'])
        self.target_path = Path(self.config['target_path'])
        # ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ì—¬ JSONì˜ cat_idì™€ íƒ€ì… ì¼ì¹˜
        self.selected_classes = set(str(cls_id) for cls_id in self.config['selected_classes'])
        self.class_mapping = self.config['class_mapping']
        self.image_size = self.config['image_size']
        self.sample_ratio = self.config['sample_ratio']
        self.max_images = self.config['max_images']
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        self.setup_directories()
    
    def setup_directories(self):
        """ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±"""
        dirs = [
            'images/train',
            'images/val',
            'labels/train',
            'labels/val'
        ]
        
        for dir_name in dirs:
            (self.target_path / dir_name).mkdir(parents=True, exist_ok=True)
        
        print(f"ğŸ“ ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±: {self.target_path}")
    
    def load_annotations(self, json_file):
        """JSON ì–´ë…¸í…Œì´ì…˜ ë¡œë“œ ë° í•„í„°ë§"""
        print(f"ğŸ“– ì–´ë…¸í…Œì´ì…˜ ë¡œë“œ ì¤‘: {json_file}")
        
        with open(json_file, 'r') as f:
            data = json.load(f)
        
        # ì¹´í…Œê³ ë¦¬ ì •ë³´
        categories = data['categories']
        images = data['images']
        annotations = data['annotations']
        
        # í•„í„°ë§ëœ ì–´ë…¸í…Œì´ì…˜ë§Œ ìˆ˜ì§‘
        filtered_annotations = defaultdict(list)
        annotation_count = 0
        
        # DeepScoresëŠ” annotationsë„ dict í˜•íƒœ
        if isinstance(annotations, dict):
            for ann_id, ann in annotations.items():
                cat_id = ann.get('cat_id')
                if cat_id:
                    # cat_idê°€ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ì²« ë²ˆì§¸ ìš”ì†Œ ì‚¬ìš©
                    if isinstance(cat_id, list):
                        cat_id = cat_id[0] if cat_id else None
                    
                    if cat_id and cat_id in self.selected_classes:
                        # DeepScoresëŠ” img_idë¥¼ ì‚¬ìš©
                        image_id = ann.get('img_id') or ann.get('image_id')
                        # DeepScoresëŠ” a_bboxë¥¼ ì‚¬ìš© (axis-aligned bbox)
                        bbox = ann.get('a_bbox') or ann.get('bbox', [0, 0, 1, 1])
                        
                        if image_id and bbox:
                            filtered_annotations[image_id].append({
                                'cat_id': cat_id,
                                'bbox': bbox,
                                'area': ann.get('area', 1)
                            })
                            annotation_count += 1
        
        print(f"âœ… í•„í„°ë§ ì™„ë£Œ: {annotation_count:,d}ê°œ ì–´ë…¸í…Œì´ì…˜, {len(filtered_annotations):,d}ê°œ ì´ë¯¸ì§€")
        return images, filtered_annotations, categories
    
    def convert_bbox_to_yolo(self, bbox, img_width, img_height):
        """DeepScores bboxë¥¼ YOLO í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        DeepScoresì˜ a_bboxëŠ” [x1, y1, x2, y2] í˜•ì‹
        """
        x1, y1, x2, y2 = bbox
        
        # width, height ê³„ì‚°
        width = abs(x2 - x1)
        height = abs(y2 - y1)
        
        # ì¤‘ì‹¬ì  ì¢Œí‘œ ê³„ì‚°
        center_x = (x1 + x2) / 2
        center_y = (y1 + y2) / 2
        
        # ì •ê·œí™”
        center_x /= img_width
        center_y /= img_height
        width /= img_width
        height /= img_height
        
        # ì¢Œí‘œê°€ 0-1 ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ì§€ ì•Šë„ë¡ í´ë¦¬í•‘
        center_x = max(0.0, min(1.0, center_x))
        center_y = max(0.0, min(1.0, center_y))
        width = max(0.0, min(1.0, width))
        height = max(0.0, min(1.0, height))
        
        return [center_x, center_y, width, height]
    
    def process_image(self, image_path, annotations, output_image_path, output_label_path):
        """ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬"""
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(str(image_path))
        if image is None:
            return False
        
        orig_height, orig_width = image.shape[:2]
        
        # ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ (ì •ì‚¬ê°í˜•ìœ¼ë¡œ)
        if orig_width != self.image_size or orig_height != self.image_size:
            # ê°€ë¡œì„¸ë¡œ ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ íŒ¨ë”© ì¶”ê°€
            scale = self.image_size / max(orig_width, orig_height)
            new_width = int(orig_width * scale)
            new_height = int(orig_height * scale)
            
            # ë¦¬ì‚¬ì´ì¦ˆ
            resized = cv2.resize(image, (new_width, new_height), interpolation=cv2.INTER_AREA)
            
            # íŒ¨ë”© ì¶”ê°€ (ê°€ìš´ë° ì •ë ¬)
            pad_x = (self.image_size - new_width) // 2
            pad_y = (self.image_size - new_height) // 2
            
            processed_image = np.full((self.image_size, self.image_size, 3), 255, dtype=np.uint8)
            processed_image[pad_y:pad_y+new_height, pad_x:pad_x+new_width] = resized
        else:
            processed_image = image.copy()
            scale = 1.0
            pad_x = pad_y = 0
        
        # ì´ë¯¸ì§€ ì €ì¥
        cv2.imwrite(str(output_image_path), processed_image)
        
        # ë¼ë²¨ ë³€í™˜ ë° ì €ì¥
        yolo_labels = []
        for ann in annotations:
            cat_id = ann['cat_id']
            bbox = ann['bbox']
            
            # ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ìƒˆë¡œìš´ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ê²Œ ì¡°ì •
            # DeepScores bboxëŠ” [x1, y1, x2, y2] í˜•ì‹
            x1, y1, x2, y2 = bbox
            
            # ì›ë³¸ ì´ë¯¸ì§€ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ëŠ” ë°”ìš´ë”© ë°•ìŠ¤ í•„í„°ë§
            if (x1 < 0 or y1 < 0 or x2 > orig_width or y2 > orig_height or
                x1 >= x2 or y1 >= y2):
                continue
            
            # ìŠ¤ì¼€ì¼ë§ ì ìš©
            x1_scaled = x1 * scale
            y1_scaled = y1 * scale
            x2_scaled = x2 * scale
            y2_scaled = y2 * scale
            
            # íŒ¨ë”© ì˜¤í”„ì…‹ ì ìš©
            x1_final = x1_scaled + pad_x
            y1_final = y1_scaled + pad_y
            x2_final = x2_scaled + pad_x
            y2_final = y2_scaled + pad_y
            
            # ë³€í™˜ëœ ì´ë¯¸ì§€ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ëŠ” ë°”ìš´ë”© ë°•ìŠ¤ í•„í„°ë§
            if (x1_final < 0 or y1_final < 0 or 
                x2_final > self.image_size or y2_final > self.image_size):
                continue
            
            # ë„ˆë¬´ ì‘ì€ ë°”ìš´ë”© ë°•ìŠ¤ í•„í„°ë§ (1í”½ì…€ ì´í•˜)
            width_final = x2_final - x1_final
            height_final = y2_final - y1_final
            if width_final < 1 or height_final < 1:
                continue
            
            # YOLO í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            yolo_bbox = self.convert_bbox_to_yolo([x1_final, y1_final, x2_final, y2_final], 
                                                 self.image_size, self.image_size)
            
            # ì¶”ê°€ ê²€ì¦: ëª¨ë“  ì¢Œí‘œê°€ ìœ íš¨í•œ ë²”ìœ„ì¸ì§€ í™•ì¸
            if all(0.0 <= coord <= 1.0 for coord in yolo_bbox):
                # í´ë˜ìŠ¤ ID ë§¤í•‘ (ë¬¸ìì—´ë¡œ ë³€í™˜)
                cat_id_str = str(cat_id)
                if cat_id_str in self.class_mapping:
                    class_id = self.class_mapping[cat_id_str]
                    yolo_labels.append(f"{class_id} {' '.join(map(str, yolo_bbox))}")
        
        # ë¼ë²¨ íŒŒì¼ ì €ì¥
        if yolo_labels:
            with open(output_label_path, 'w') as f:
                f.write('\n'.join(yolo_labels))
        else:
            # ë¹ˆ ë¼ë²¨ íŒŒì¼ ìƒì„±
            output_label_path.touch()
        
        return True
    
    def process_split(self, json_file, split_name, max_images_per_split):
        """ë°ì´í„° ë¶„í•  ì²˜ë¦¬"""
        print(f"\nğŸ”„ {split_name} ë°ì´í„° ì²˜ë¦¬ ì¤‘...")
        
        # ì–´ë…¸í…Œì´ì…˜ ë¡œë“œ
        images, filtered_annotations, categories = self.load_annotations(json_file)
        
        # ì´ë¯¸ì§€ ìƒ˜í”Œë§
        image_list = list(filtered_annotations.keys())
        if len(image_list) > max_images_per_split:
            image_list = random.sample(image_list, max_images_per_split)
        
        print(f"ğŸ“Š ì²˜ë¦¬í•  ì´ë¯¸ì§€ ìˆ˜: {len(image_list):,d}")
        
        # ì¶œë ¥ ê²½ë¡œ ì„¤ì •
        image_output_dir = self.target_path / 'images' / split_name
        label_output_dir = self.target_path / 'labels' / split_name
        
        processed_count = 0
        skipped_count = 0
        
        # ì´ë¯¸ì§€ ì²˜ë¦¬
        for image_id in tqdm(image_list, desc=f"Processing {split_name}"):
            # ì´ë¯¸ì§€ ì •ë³´ ì°¾ê¸° (DeepScoresëŠ” ë¬¸ìì—´ í‚¤ ì‚¬ìš©)
            image_info = None
            if isinstance(images, dict):
                # ë¬¸ìì—´ê³¼ ì •ìˆ˜ ë‘˜ ë‹¤ ì‹œë„
                image_info = images.get(str(image_id)) or images.get(image_id)
            else:
                for img in images:
                    if img.get('id') == image_id or str(img.get('id')) == str(image_id):
                        image_info = img
                        break
            
            if not image_info:
                skipped_count += 1
                continue
            
            # íŒŒì¼ ê²½ë¡œ
            filename = image_info.get('filename') or image_info.get('file_name', f"{image_id}.png")
            image_path = self.source_path / 'images' / filename
            
            if not image_path.exists():
                skipped_count += 1
                continue
            
            # ì¶œë ¥ ê²½ë¡œ
            output_image_path = image_output_dir / filename
            output_label_path = label_output_dir / (Path(filename).stem + '.txt')
            
            # ì´ë¯¸ì§€ ì²˜ë¦¬
            if self.process_image(image_path, filtered_annotations[image_id], 
                                 output_image_path, output_label_path):
                processed_count += 1
            else:
                skipped_count += 1
        
        print(f"âœ… {split_name} ì™„ë£Œ: {processed_count:,d}ê°œ ì²˜ë¦¬, {skipped_count:,d}ê°œ ìŠ¤í‚µ")
        return processed_count
    
    def run(self):
        """ì „ì²´ ì „ì²˜ë¦¬ ì‹¤í–‰"""
        print("ğŸš€ Stage 1 ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘")
        print(f"ğŸ“ ì†ŒìŠ¤: {self.source_path}")
        print(f"ğŸ“ íƒ€ê²Ÿ: {self.target_path}")
        print(f"ğŸ¯ ì„ íƒëœ í´ë˜ìŠ¤: {len(self.selected_classes)}ê°œ")
        print(f"ğŸ“ ì´ë¯¸ì§€ í¬ê¸°: {self.image_size}x{self.image_size}")
        print(f"ğŸ“Š ìƒ˜í”Œë§ ë¹„ìœ¨: {self.sample_ratio*100:.1f}%")
        
        # ëœë¤ ì‹œë“œ ì„¤ì •
        random.seed(42)
        
        # JSON íŒŒì¼ ëª©ë¡
        json_files = list(self.source_path.glob("deepscores-complete-*.json"))
        if not json_files:
            print("âŒ JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
            return
        
        print(f"ğŸ“„ ë°œê²¬ëœ JSON íŒŒì¼: {len(json_files)}ê°œ")
        
        # ê° ë¶„í• ë³„ ìµœëŒ€ ì´ë¯¸ì§€ ìˆ˜ ê³„ì‚°
        total_splits = len(json_files)
        max_images_per_split = self.max_images // total_splits
        
        processed_total = 0
        
        # ê° JSON íŒŒì¼ ì²˜ë¦¬ (train/val ë¶„í• )
        for i, json_file in enumerate(json_files):
            split_name = 'train' if i < len(json_files) * 0.8 else 'val'
            processed = self.process_split(json_file, split_name, max_images_per_split)
            processed_total += processed
        
        print(f"\nğŸ‰ ì „ì²˜ë¦¬ ì™„ë£Œ!")
        print(f"ğŸ“Š ì´ ì²˜ë¦¬ëœ ì´ë¯¸ì§€: {processed_total:,d}ê°œ")
        print(f"ğŸ’¾ ì¶œë ¥ ìœ„ì¹˜: {self.target_path}")
        
        # í†µê³„ ì €ì¥
        stats = {
            'total_processed': processed_total,
            'selected_classes': len(self.selected_classes),
            'image_size': self.image_size,
            'sample_ratio': self.sample_ratio,
            'max_images': self.max_images
        }
        
        with open(self.target_path / 'preprocessing_stats.json', 'w') as f:
            json.dump(stats, f, indent=2)

if __name__ == "__main__":
    # ì „ì²˜ë¦¬ ì‹¤í–‰
    preprocessor = Stage1Preprocessor()
    preprocessor.run()