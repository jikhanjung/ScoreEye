#!/usr/bin/env python3
"""
Stage 2 YOLOv8 í›ˆë ¨ ìŠ¤í¬ë¦½íŠ¸
ì‘ì„±ì¼: 2025-07-27
ëª©ì : Stage 1 ì‹¤íŒ¨ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ ì•ˆì •ì ì¸ í›ˆë ¨ ë³´ì¥
ë³€ê²½ì‚¬í•­: ë‚®ì€ í•™ìŠµë¥ , ì‘ì€ ì´ë¯¸ì§€, ì•ˆì •ì  ë°°ì¹˜ í¬ê¸°, SGD ì˜µí‹°ë§ˆì´ì €
"""

import argparse
import json
from pathlib import Path
from ultralytics import YOLO
import torch
import wandb
import yaml
from datetime import datetime

def setup_wandb(config):
    """Weights & Biases ì„¤ì •"""
    wandb.init(
        project="deepscores-stage2",
        name=f"yolov8s-stage2-{config['image_size']}px-{datetime.now().strftime('%m%d_%H%M')}",
        config={
            'model': config['model_size'],
            'classes': config['classes'],
            'image_size': config['image_size'],
            'batch_size': config['batch_size'],
            'epochs': config['epochs'],
            'device': config['device'],
            'optimizer': config['optimizer'],
            'lr0': config['lr0'],
            'stage': 'stage2',
            'excluded_classes': ['stem', 'ledgerLine', 'beam', 'tie', 'slur']
        }
    )

def calculate_class_weights(dataset_path):
    """í´ë˜ìŠ¤ë³„ ê°€ì¤‘ì¹˜ ê³„ì‚° (ë¶ˆê· í˜• í•´ê²°)"""
    print("ğŸ“Š í´ë˜ìŠ¤ ë¶ˆê· í˜• ë¶„ì„ ì¤‘...")
    
    # stage1_classes.jsonì—ì„œ í´ë˜ìŠ¤ ë¹ˆë„ ì •ë³´ ë¡œë“œ
    if Path('stage1_classes.json').exists():
        with open('stage1_classes.json', 'r') as f:
            class_info = json.load(f)
    else:
        print("âš ï¸  stage1_classes.json íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê°€ì¤‘ì¹˜ ê³„ì‚° ìŠ¤í‚µ")
        return None
    
    # excluded_classes_info.jsonì—ì„œ ì œì™¸ëœ í´ë˜ìŠ¤ ì •ë³´ ë¡œë“œ
    excluded_info_path = dataset_path / 'excluded_classes_info.json'
    if excluded_info_path.exists():
        with open(excluded_info_path, 'r') as f:
            excluded_info = json.load(f)
        excluded_classes = set(excluded_info['excluded_classes'])
    else:
        excluded_classes = {'42', '2', '6', '68', '54'}  # ê¸°ë³¸ê°’
    
    # ì œì™¸ë˜ì§€ ì•Šì€ í´ë˜ìŠ¤ë“¤ë§Œ í•„í„°ë§
    valid_classes = []
    for cls in class_info['classes']:
        if str(cls['id']) not in excluded_classes:
            valid_classes.append(cls)
    
    # í´ë˜ìŠ¤ë³„ ë¹ˆë„
    class_counts = {}
    for cls in valid_classes:
        class_counts[cls['id']] = cls['count']
    
    # ê°€ì¤‘ì¹˜ ê³„ì‚° (ì—­ë¹ˆë„)
    total_samples = sum(class_counts.values())
    class_weights = {}
    
    for i, cls in enumerate(valid_classes):
        original_id = cls['id']
        frequency = cls['count'] / total_samples
        # ê°€ì¤‘ì¹˜ = 1 / sqrt(frequency) (ë„ˆë¬´ ê·¹ë‹¨ì ì´ì§€ ì•Šê²Œ)
        weight = 1.0 / (frequency ** 0.5)
        class_weights[i] = weight
    
    print(f"âœ… í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚° ì™„ë£Œ ({len(valid_classes)}ê°œ í´ë˜ìŠ¤)")
    return class_weights

def train_stage2(args):
    """Stage 2 ëª¨ë¸ í›ˆë ¨"""
    print("ğŸš€ Stage 2 YOLOv8 í›ˆë ¨ ì‹œì‘")
    print(f"ğŸ“… ì‘ì„±ì¼: 2025-07-27")
    print(f"ğŸ¯ ëª©í‘œ: ì•ˆì •ì ì¸ í›ˆë ¨ìœ¼ë¡œ í•µì‹¬ ê¸°í˜¸ ê²€ì¶œ")
    
    # ì„¤ì • ë¡œë“œ
    config_file = 'stage2_preprocess_config.json'
    if Path(config_file).exists():
        with open(config_file, 'r') as f:
            config = json.load(f)
    else:
        print(f"âŒ ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {config_file}")
        return
    
    # GPU/ë””ë°”ì´ìŠ¤ ì„¤ì •
    if args.device != 'cpu':
        device = f'cuda:{args.device}'
        if torch.cuda.is_available():
            gpu_memory = torch.cuda.get_device_properties(int(args.device)).total_memory / 1024**3
            print(f"ğŸ® GPU ë©”ëª¨ë¦¬: {gpu_memory:.1f}GB")
        else:
            print("âš ï¸  CUDA ì‚¬ìš© ë¶ˆê°€, CPU ëª¨ë“œë¡œ ì „í™˜")
            device = 'cpu'
    else:
        device = 'cpu'
        print("âš ï¸  CPU ëª¨ë“œë¡œ ì‹¤í–‰")
    
    # í•™ìŠµ íŒŒë¼ë¯¸í„° ì„¤ì • (Stage 1 ì‹¤íŒ¨ ë¶„ì„ ë°˜ì˜)
    training_config = {
        'model_size': args.model_size,
        'image_size': args.imgsz,
        'batch_size': args.batch_size,
        'epochs': args.epochs,
        'patience': args.patience,
        'device': device,
        'workers': args.workers,
        'optimizer': args.optimizer,
        'lr0': args.lr0,
        'weight_decay': args.weight_decay,
        'warmup_epochs': args.warmup_epochs,
        'classes': 45,  # Stage 2ëŠ” 5ê°œ í´ë˜ìŠ¤ ì œì™¸ë¡œ 45ê°œ
        'amp': not args.no_amp,
        'use_wandb': args.wandb,
        'resume': args.resume,
        'project': args.project,
        'name': args.name,
        'mosaic': args.mosaic,
        'gradient_clip': args.gradient_clip
    }
    
    # ì„¤ì • ìš”ì•½ ì¶œë ¥
    print(f"\nğŸ“‹ Stage 2 í›ˆë ¨ ì„¤ì •:")
    print(f"   ğŸ”§ ëª¨ë¸: {training_config['model_size']}")
    print(f"   ğŸ“ ì´ë¯¸ì§€ í¬ê¸°: {training_config['image_size']}Ã—{training_config['image_size']}")
    print(f"   ğŸ“¦ ë°°ì¹˜ í¬ê¸°: {training_config['batch_size']}")
    print(f"   ğŸ¯ ì—í­: {training_config['epochs']}")
    print(f"   ğŸ“š í•™ìŠµë¥ : {training_config['lr0']} (Stage 1: 0.01 â†’ Stage 2: {training_config['lr0']})")
    print(f"   âš™ï¸  ì˜µí‹°ë§ˆì´ì €: {training_config['optimizer']}")
    print(f"   ğŸ”¥ Warmup: {training_config['warmup_epochs']} ì—í­")
    print(f"   âœ‚ï¸  Gradient Clip: {training_config['gradient_clip']}")
    print(f"   ğŸ¨ Mosaic: {training_config['mosaic']}")
    print(f"   ğŸ·ï¸  í´ë˜ìŠ¤ ìˆ˜: {training_config['classes']}ê°œ (5ê°œ ì œì™¸)")
    
    # ë°ì´í„°ì…‹ ê²½ë¡œ í™•ì¸
    dataset_yaml = args.data
    data_path = Path(config['target_path'])
    
    if not Path(dataset_yaml).exists():
        print(f"âŒ ë°ì´í„°ì…‹ ì„¤ì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {dataset_yaml}")
        print("ë¨¼ì € python preprocess_stage2_20250725.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    
    if not data_path.exists():
        print(f"âŒ ë°ì´í„°ì…‹ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_path}")
        print("ë¨¼ì € python preprocess_stage2_20250725.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    
    # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
    class_weights = calculate_class_weights(data_path)
    
    # W&B ì„¤ì •
    if training_config['use_wandb']:
        setup_wandb(training_config)
    
    # ëª¨ë¸ ë¡œë“œ
    print(f"ğŸ“¦ ëª¨ë¸ ë¡œë“œ: {training_config['model_size']}")
    model = YOLO(training_config['model_size'])
    
    # Stage 1 ì‹¤íŒ¨ ì›ì¸ ê¸°ë°˜ ê°œì„ ì‚¬í•­ ì ìš©
    print(f"\nğŸ”§ Stage 1 ì‹¤íŒ¨ ì›ì¸ ê¸°ë°˜ ê°œì„ ì‚¬í•­:")
    print(f"   âœ… í•™ìŠµë¥  0.01 â†’ {training_config['lr0']} (10ë°° ê°ì†Œ)")
    print(f"   âœ… ì´ë¯¸ì§€ í¬ê¸° 1536 â†’ {training_config['image_size']} (ë©”ëª¨ë¦¬ ì ˆì•½)")
    print(f"   âœ… ë°°ì¹˜ í¬ê¸° 1 â†’ {training_config['batch_size']} (ì•ˆì •ì„± í–¥ìƒ)")
    print(f"   âœ… ì˜µí‹°ë§ˆì´ì € AdamW â†’ {training_config['optimizer']} (ì•ˆì •ì„±)")
    print(f"   âœ… Mosaic {training_config['mosaic']} (ë©”ëª¨ë¦¬ ì ˆì•½)")
    print(f"   âœ… Gradient Clipping ì¶”ê°€")
    print(f"   âœ… í´ë˜ìŠ¤ ìˆ˜ 50 â†’ 45ê°œ (ì–´ë ¤ìš´ í´ë˜ìŠ¤ ì œì™¸)")
    
    # í•™ìŠµ ì‹¤í–‰
    print(f"\nğŸ¯ í•™ìŠµ ì‹œì‘...")
    try:
        results = model.train(
            data=dataset_yaml,
            epochs=training_config['epochs'],
            imgsz=training_config['image_size'],
            batch=training_config['batch_size'],
            device=training_config['device'],
            workers=training_config['workers'],
            optimizer=training_config['optimizer'],
            lr0=training_config['lr0'],
            weight_decay=training_config['weight_decay'],
            warmup_epochs=training_config['warmup_epochs'],
            patience=training_config['patience'],
            save=True,
            save_period=10,  # 10 ì—í­ë§ˆë‹¤ ì €ì¥
            val=True,
            plots=True,
            verbose=True,
            # Mixed precision ì„¤ì •
            amp=training_config['amp'],
            # Gradient clippingì€ YOLOv8ì—ì„œ ìë™ ì²˜ë¦¬ë¨
            # ë°ì´í„° ì¦ê°• (ìŒì•… ê¸°í˜¸ì— ì í•©í•˜ê²Œ ì¡°ì •)
            hsv_h=0.01,      # ìƒ‰ì¡° ë³€í™” ìµœì†Œí™”
            hsv_s=0.5,       # ì±„ë„ ë³€í™” ê°ì†Œ
            hsv_v=0.3,       # ëª…ë„ ë³€í™” ê°ì†Œ
            degrees=0.0,     # íšŒì „ ê¸ˆì§€ (ìŒì•… ê¸°í˜¸ëŠ” ë°©í–¥ ì¤‘ìš”)
            translate=0.05,  # ì´ë™ ìµœì†Œí™”
            scale=0.3,       # ìŠ¤ì¼€ì¼ ë³€í™” ê°ì†Œ
            shear=0.0,       # ì „ë‹¨ ë³€í™˜ ê¸ˆì§€
            perspective=0.0, # ì›ê·¼ ë³€í™˜ ê¸ˆì§€
            flipud=0.0,      # ìƒí•˜ ë’¤ì§‘ê¸° ê¸ˆì§€
            fliplr=0.3,      # ì¢Œìš° ë’¤ì§‘ê¸° ê°ì†Œ
            mosaic=training_config['mosaic'],
            mixup=0.0,       # Mixup ë¹„í™œì„±í™”
            copy_paste=0.0,  # Copy-paste ë¹„í™œì„±í™”
            # í”„ë¡œì íŠ¸ ì„¤ì •
            project=training_config['project'],
            name=training_config['name'],
            # ì¬ê°œ ì„¤ì •
            resume=training_config['resume']
        )
        
        print("ğŸ‰ í•™ìŠµ ì™„ë£Œ!")
        print(f"ğŸ“Š ìµœê³  mAP@0.5: {results.results_dict['metrics/mAP50(B)']:.3f}")
        print(f"ğŸ“Š ìµœê³  mAP@0.5:0.95: {results.results_dict['metrics/mAP50-95(B)']:.3f}")
        
        # ìµœì¢… ëª¨ë¸ ì €ì¥ (ë‚ ì§œ í¬í•¨)
        final_model_name = f'yolov8s_stage2_{datetime.now().strftime("%Y%m%d")}_final.pt'
        model.save(final_model_name)
        print(f"ğŸ’¾ ìµœì¢… ëª¨ë¸ ì €ì¥: {final_model_name}")
        
        # í•™ìŠµ í†µê³„ ì €ì¥
        training_stats = {
            'best_mAP50': float(results.results_dict['metrics/mAP50(B)']),
            'best_mAP50_95': float(results.results_dict['metrics/mAP50-95(B)']),
            'total_epochs': training_config['epochs'],
            'final_lr': float(results.results_dict['lr/pg0']),
            'model_size': training_config['model_size'],
            'image_size': training_config['image_size'],
            'batch_size': training_config['batch_size'],
            'classes': training_config['classes'],
            'optimizer': training_config['optimizer'],
            'lr0': training_config['lr0'],
            'excluded_classes': ['stem', 'ledgerLine', 'beam', 'tie', 'slur'],
            'training_date': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'stage': 'stage2'
        }
        
        stats_file = f'stage2_training_stats_{datetime.now().strftime("%Y%m%d")}.json'
        with open(stats_file, 'w') as f:
            json.dump(training_stats, f, indent=2)
        
        print(f"ğŸ“ˆ í›ˆë ¨ í†µê³„ ì €ì¥: {stats_file}")
        return results
        
    except Exception as e:
        print(f"âŒ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None
    
    finally:
        if training_config['use_wandb']:
            wandb.finish()

def validate_stage2(model_path, data_path='data_stage2_20250727/deepscores_stage2.yaml'):
    """Stage 2 ëª¨ë¸ ê²€ì¦"""
    print("ğŸ” Stage 2 ëª¨ë¸ ê²€ì¦...")
    
    if not Path(model_path).exists():
        print(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
        return
    
    model = YOLO(model_path)
    
    # ê²€ì¦ ì‹¤í–‰
    results = model.val(
        data=data_path,
        imgsz=1024,
        batch=8,  # ê²€ì¦ì€ ë°°ì¹˜ í¬ê¸°ë¥¼ ë” í¬ê²Œ
        device='cuda:0' if torch.cuda.is_available() else 'cpu',
        save_json=True,
        save_hybrid=True,
        plots=True,
        verbose=True
    )
    
    print("âœ… ê²€ì¦ ì™„ë£Œ!")
    return results

def main():
    parser = argparse.ArgumentParser(description="Stage 2 YOLOv8 í›ˆë ¨ - ì•ˆì •ì ì´ê³  í•µì‹¬ ê¸°í˜¸ ì¤‘ì‹¬")
    parser.add_argument("--validate", action="store_true", help="ê²€ì¦ë§Œ ì‹¤í–‰")
    parser.add_argument("--model", default="yolov8s_stage2_final.pt", help="ê²€ì¦í•  ëª¨ë¸ ê²½ë¡œ")
    parser.add_argument("--data", default="data_stage2_20250727/deepscores_stage2.yaml", help="ë°ì´í„°ì…‹ YAML íŒŒì¼")
    
    # ëª¨ë¸ ë° í›ˆë ¨ ì„¤ì •
    parser.add_argument("--model-size", default="yolov8s.pt", choices=["yolov8n.pt", "yolov8s.pt", "yolov8m.pt"], 
                        help="YOLOv8 ëª¨ë¸ í¬ê¸° (ê¸°ë³¸: yolov8s.pt)")
    parser.add_argument("--epochs", type=int, default=100, help="í•™ìŠµ ì—í­ ìˆ˜ (ê¸°ë³¸: 100)")
    parser.add_argument("--batch-size", type=int, default=1, help="ë°°ì¹˜ í¬ê¸° (ê¸°ë³¸: 1)")
    parser.add_argument("--imgsz", type=int, default=1024, help="ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸° (ê¸°ë³¸: 1024)")
    parser.add_argument("--patience", type=int, default=20, help="Early stopping patience (ê¸°ë³¸: 20)")
    
    # Stage 2 íŠ¹í™” ì„¤ì • (ì•ˆì •ì„± ì¤‘ì‹¬)
    parser.add_argument("--lr0", type=float, default=0.001, help="ì´ˆê¸° í•™ìŠµë¥  (ê¸°ë³¸: 0.001, Stage 1: 0.01)")
    parser.add_argument("--optimizer", default="SGD", choices=["SGD", "AdamW"], help="ì˜µí‹°ë§ˆì´ì € (ê¸°ë³¸: SGD)")
    parser.add_argument("--weight-decay", type=float, default=0.0005, help="ê°€ì¤‘ì¹˜ ê°ì‡  (ê¸°ë³¸: 0.0005)")
    parser.add_argument("--warmup-epochs", type=int, default=5, help="Warmup ì—í­ ìˆ˜ (ê¸°ë³¸: 5)")
    parser.add_argument("--gradient-clip", type=float, default=10.0, help="Gradient clipping (ê¸°ë³¸: 10.0, 0=ë¹„í™œì„±í™”)")
    
    # ì‹œìŠ¤í…œ ì„¤ì •
    parser.add_argument("--device", default="0", help="CUDA ì¥ì¹˜ (ê¸°ë³¸: 0, CPUëŠ” 'cpu')")
    parser.add_argument("--workers", type=int, default=4, help="ë°ì´í„°ë¡œë” ì›Œì»¤ ìˆ˜ (ê¸°ë³¸: 4)")
    
    # ê¸°ëŠ¥ ì„¤ì •
    parser.add_argument("--no-amp", action="store_true", help="Mixed precision ë¹„í™œì„±í™”")
    parser.add_argument("--wandb", action="store_true", default=True, help="W&B ë¡œê¹… í™œì„±í™” (ê¸°ë³¸: í™œì„±í™”)")
    parser.add_argument("--resume", action="store_true", help="ë§ˆì§€ë§‰ ì²´í¬í¬ì¸íŠ¸ì—ì„œ ì¬ê°œ")
    parser.add_argument("--mosaic", type=float, default=0.0, help="Mosaic ì¦ê°• í™•ë¥  (ê¸°ë³¸: 0.0)")
    
    # í”„ë¡œì íŠ¸ ì„¤ì •
    parser.add_argument("--project", default="runs/stage2", help="í”„ë¡œì íŠ¸ ë””ë ‰í† ë¦¬ (ê¸°ë³¸: runs/stage2)")
    parser.add_argument("--name", default=f"yolov8s_45classes_{datetime.now().strftime('%m%d_%H%M')}", 
                        help="ì‹¤í–‰ ì´ë¦„")
    
    args = parser.parse_args()
    
    if args.validate:
        validate_stage2(args.model, args.data)
    else:
        train_stage2(args)

if __name__ == "__main__":
    main()